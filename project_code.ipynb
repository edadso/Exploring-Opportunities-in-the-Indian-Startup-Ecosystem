{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding\n",
    "By [THE TIMES OF INDIA](https://timesofindia.indiatimes.com/business/india-business/india-becomes-third-largest-startup-ecosystem-in-the-world/articleshow/85871428.cms), India has emerged as the third largest startup ecosystem in the world after US and China. Following this, our team aims to strategically enter the Indian Startup Ecosystem by leveraging data-driven insights to identify high-potential opportunities. Through comprehensive research and analysis, we seek to gain insight into funding received by startups in India from 2018 to 2021.\n",
    "\n",
    "#### Hypothesis\n",
    "**Null Hypothesis (Ho):** The sector of a startup has no significant influence on the funding it receives.<br>\n",
    "\n",
    "**Alternative Hypothesis (Ha):** The sector of a startup has significant influence on the funding it receives.\n",
    "\n",
    "# Data Understanding\n",
    "This data provides information into amount of money startups received from 2018 to 2021, the sector of startups, headquaters, what a startup do, the year of establishment, startup name, investors, and stage.<br>\n",
    "\n",
    "`Feature Description`:\n",
    "- **Company_Brand:** Name of startup\n",
    "- **Founded:** Year of establishment\n",
    "- **HeadQuater:** Location of startup Headquater\n",
    "- **Sector:** Sector or industry of startup\n",
    "- **What_it_does:** what the startup does\n",
    "- **Founders:** Name od founder\n",
    "- **Investors:** Name of investor\n",
    "- **Amount:** Amount of investment in USD and INR\n",
    "- **Statge:** Phase of development (eg. Ideation Stage, Pre-Seed Stage, Seed Stage, Early Stage (Series A, B, etc.))\n",
    "- **Year:** Year startup received funding\n",
    "\n",
    "#### Analytical Questions\n",
    "1. How is funding spread across the years?\n",
    "2. What are the dominant sectors within the Indian startup ecosystem across the years?\n",
    "3. Are there any emerging sectors that have shown a significant increase in funding year over year?\n",
    "4. Where in India could be considered the surviving grounds for startups?\n",
    "5. How does the startup's location influence its funding and growth opportunities?\n",
    "6. Is there a relationship between what a startup does and the funding it receives?\n",
    "7. Is there a correlation between the year a startup received funding and the amount of funding it received?\n",
    "8. Which cities or regions have the highest concentration of funded startups?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necesary libraries and packages\n",
    "import pyodbc\n",
    "from dotenv import dotenv_values #import the dotenv_values function from the dotenv package\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Environment Variables and Create SQL Server Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "environment_variables = dotenv_values('.env')\n",
    "# Access login credentials from  the '.env' file\n",
    "server = environment_variables.get(\"SERVER\")\n",
    "database = environment_variables.get(\"DATABASE\")\n",
    "username = environment_variables.get(\"UID\")\n",
    "password = environment_variables.get(\"PWD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create Connection connection string\n",
    "connection_string = f\"DRIVER={{SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password}\"\n",
    "\n",
    "# connect to the server using pyodbc\n",
    "connection = pyodbc.connect(connection_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write querry to retrieve tables from database\n",
    "query1 = \"Select * from dbo.LP1_startup_funding2020\"\n",
    "query2 = \"Select * from dbo.LP1_startup_funding2021\"\n",
    "\n",
    "# Retrieve dataset from database with connection created\n",
    "df_2020 = pd.read_sql(query1, connection)\n",
    "df_2021 = pd.read_sql(query2, connection)\n",
    "\n",
    "# Load CSV files\n",
    "df_2018 = pd.read_csv('Data\\startup_funding2018.csv')\n",
    "df_2019 = pd.read_csv('Data\\startup_funding2019.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2020 Dataset Exploration and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Brand</th>\n",
       "      <th>Founded</th>\n",
       "      <th>HeadQuarter</th>\n",
       "      <th>Sector</th>\n",
       "      <th>What_it_does</th>\n",
       "      <th>Founders</th>\n",
       "      <th>Investor</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Stage</th>\n",
       "      <th>column10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aqgromalin</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>AgriTech</td>\n",
       "      <td>Cultivating Ideas for Profit</td>\n",
       "      <td>Prasanna Manogaran, Bharani C L</td>\n",
       "      <td>Angel investors</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Krayonnz</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>EdTech</td>\n",
       "      <td>An academy-guardian-scholar centric ecosystem ...</td>\n",
       "      <td>Saurabh Dixit, Gurudutt Upadhyay</td>\n",
       "      <td>GSF Accelerator</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>Pre-seed</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PadCare Labs</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Hygiene management</td>\n",
       "      <td>Converting bio-hazardous waste to harmless waste</td>\n",
       "      <td>Ajinkya Dhariya</td>\n",
       "      <td>Venture Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pre-seed</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Company_Brand  Founded HeadQuarter              Sector  \\\n",
       "0    Aqgromalin   2019.0     Chennai            AgriTech   \n",
       "1      Krayonnz   2019.0   Bangalore              EdTech   \n",
       "2  PadCare Labs   2018.0        Pune  Hygiene management   \n",
       "\n",
       "                                        What_it_does  \\\n",
       "0                       Cultivating Ideas for Profit   \n",
       "1  An academy-guardian-scholar centric ecosystem ...   \n",
       "2   Converting bio-hazardous waste to harmless waste   \n",
       "\n",
       "                           Founders         Investor    Amount     Stage  \\\n",
       "0   Prasanna Manogaran, Bharani C L  Angel investors  200000.0      None   \n",
       "1  Saurabh Dixit, Gurudutt Upadhyay  GSF Accelerator  100000.0  Pre-seed   \n",
       "2                   Ajinkya Dhariya   Venture Center       NaN  Pre-seed   \n",
       "\n",
       "  column10  \n",
       "0     None  \n",
       "1     None  \n",
       "2     None  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview dataframe\n",
    "df_2020.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1055 entries, 0 to 1054\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Company_Brand  1055 non-null   object \n",
      " 1   Founded        842 non-null    float64\n",
      " 2   HeadQuarter    961 non-null    object \n",
      " 3   Sector         1042 non-null   object \n",
      " 4   What_it_does   1055 non-null   object \n",
      " 5   Founders       1043 non-null   object \n",
      " 6   Investor       1017 non-null   object \n",
      " 7   Amount         801 non-null    float64\n",
      " 8   Stage          591 non-null    object \n",
      " 9   column10       2 non-null      object \n",
      "dtypes: float64(2), object(8)\n",
      "memory usage: 82.5+ KB\n",
      "None \n",
      "====================== Null Value Percentage ==========================\n",
      "               null_value_count  percentage_null_value\n",
      "Company_Brand                 0               0.000000\n",
      "Founded                     213              20.189573\n",
      "HeadQuarter                  94               8.909953\n",
      "Sector                       13               1.232227\n",
      "What_it_does                  0               0.000000\n",
      "Founders                     12               1.137441\n",
      "Investor                     38               3.601896\n",
      "Amount                      254              24.075829\n",
      "Stage                       464              43.981043\n",
      "column10                   1053              99.810427 \n",
      "====================== Duplicated rows ======================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Brand</th>\n",
       "      <th>Founded</th>\n",
       "      <th>HeadQuarter</th>\n",
       "      <th>Sector</th>\n",
       "      <th>What_it_does</th>\n",
       "      <th>Founders</th>\n",
       "      <th>Investor</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Stage</th>\n",
       "      <th>column10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Krimanshi</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Jodhpur</td>\n",
       "      <td>Biotechnology company</td>\n",
       "      <td>Krimanshi aims to increase rural income by imp...</td>\n",
       "      <td>Nikhil Bohra</td>\n",
       "      <td>Rajasthan Venture Capital Fund, AIM Smart City</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>Seed</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Nykaa</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Cosmetics</td>\n",
       "      <td>Nykaa is an online marketplace for different b...</td>\n",
       "      <td>Falguni Nayar</td>\n",
       "      <td>Alia Bhatt, Katrina Kaif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>Byju’s</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>EdTech</td>\n",
       "      <td>An Indian educational technology and online tu...</td>\n",
       "      <td>Byju Raveendran</td>\n",
       "      <td>Owl Ventures, Tiger Global Management</td>\n",
       "      <td>500000000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company_Brand  Founded HeadQuarter                 Sector  \\\n",
       "145     Krimanshi   2015.0     Jodhpur  Biotechnology company   \n",
       "205         Nykaa   2012.0      Mumbai              Cosmetics   \n",
       "362        Byju’s   2011.0   Bangalore                 EdTech   \n",
       "\n",
       "                                          What_it_does         Founders  \\\n",
       "145  Krimanshi aims to increase rural income by imp...     Nikhil Bohra   \n",
       "205  Nykaa is an online marketplace for different b...    Falguni Nayar   \n",
       "362  An Indian educational technology and online tu...  Byju Raveendran   \n",
       "\n",
       "                                           Investor       Amount Stage  \\\n",
       "145  Rajasthan Venture Capital Fund, AIM Smart City     600000.0  Seed   \n",
       "205                        Alia Bhatt, Katrina Kaif          NaN  None   \n",
       "362           Owl Ventures, Tiger Global Management  500000000.0  None   \n",
       "\n",
       "    column10  \n",
       "145     None  \n",
       "205     None  \n",
       "362     None  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check characteristics of dataframe\n",
    "print(df_2020.info(), \"\\n====================== Null Value Percentage ==========================\")\n",
    "# Check for null values\n",
    "print(pd.DataFrame({\"null_value_count\": df_2020.isna().sum(), \"percentage_null_value\": df_2020.isna().mean().mul(100) }), \"\\n====================== Duplicated rows ======================\")\n",
    "# Check for duplicate\n",
    "df_2020.loc[df_2020.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicated rows from DataFrame\n",
    "df_2020.drop_duplicates(keep = \"first\", inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column10 has 99.8% null values so we drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Company_Brand', 'Founded', 'HeadQuarter', 'Sector', 'What_it_does',\n",
       "       'Founders', 'Investor', 'Amount', 'Stage'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop columns10\n",
    "df_2020.drop(columns = [\"column10\"], inplace = True)\n",
    "# Preview remaining columns \n",
    "df_2020.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2021 Dataset Exploration and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Brand</th>\n",
       "      <th>Founded</th>\n",
       "      <th>HeadQuarter</th>\n",
       "      <th>Sector</th>\n",
       "      <th>What_it_does</th>\n",
       "      <th>Founders</th>\n",
       "      <th>Investor</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unbox Robotics</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>AI startup</td>\n",
       "      <td>Unbox Robotics builds on-demand AI-driven ware...</td>\n",
       "      <td>Pramod Ghadge, Shahid Memon</td>\n",
       "      <td>BEENEXT, Entrepreneur First</td>\n",
       "      <td>$1,200,000</td>\n",
       "      <td>Pre-series A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>upGrad</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>EdTech</td>\n",
       "      <td>UpGrad is an online higher education platform.</td>\n",
       "      <td>Mayank Kumar, Phalgun Kompalli, Ravijot Chugh,...</td>\n",
       "      <td>Unilazer Ventures, IIFL Asset Management</td>\n",
       "      <td>$120,000,000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lead School</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>EdTech</td>\n",
       "      <td>LEAD School offers technology based school tra...</td>\n",
       "      <td>Smita Deorah, Sumeet Mehta</td>\n",
       "      <td>GSV Ventures, Westbridge Capital</td>\n",
       "      <td>$30,000,000</td>\n",
       "      <td>Series D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company_Brand  Founded HeadQuarter      Sector  \\\n",
       "0  Unbox Robotics   2019.0   Bangalore  AI startup   \n",
       "1          upGrad   2015.0      Mumbai      EdTech   \n",
       "2     Lead School   2012.0      Mumbai      EdTech   \n",
       "\n",
       "                                        What_it_does  \\\n",
       "0  Unbox Robotics builds on-demand AI-driven ware...   \n",
       "1     UpGrad is an online higher education platform.   \n",
       "2  LEAD School offers technology based school tra...   \n",
       "\n",
       "                                            Founders  \\\n",
       "0                        Pramod Ghadge, Shahid Memon   \n",
       "1  Mayank Kumar, Phalgun Kompalli, Ravijot Chugh,...   \n",
       "2                         Smita Deorah, Sumeet Mehta   \n",
       "\n",
       "                                   Investor        Amount         Stage  \n",
       "0               BEENEXT, Entrepreneur First    $1,200,000  Pre-series A  \n",
       "1  Unilazer Ventures, IIFL Asset Management  $120,000,000          None  \n",
       "2          GSV Ventures, Westbridge Capital   $30,000,000      Series D  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview dataframe\n",
    "df_2021.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1209 entries, 0 to 1208\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Company_Brand  1209 non-null   object \n",
      " 1   Founded        1208 non-null   float64\n",
      " 2   HeadQuarter    1208 non-null   object \n",
      " 3   Sector         1209 non-null   object \n",
      " 4   What_it_does   1209 non-null   object \n",
      " 5   Founders       1205 non-null   object \n",
      " 6   Investor       1147 non-null   object \n",
      " 7   Amount         1206 non-null   object \n",
      " 8   Stage          781 non-null    object \n",
      "dtypes: float64(1), object(8)\n",
      "memory usage: 85.1+ KB\n",
      "None \n",
      "====================== Null Value Percentage ======================\n",
      "               null_value_count  percentage_null_value\n",
      "Company_Brand                 0               0.000000\n",
      "Founded                       1               0.082713\n",
      "HeadQuarter                   1               0.082713\n",
      "Sector                        0               0.000000\n",
      "What_it_does                  0               0.000000\n",
      "Founders                      4               0.330852\n",
      "Investor                     62               5.128205\n",
      "Amount                        3               0.248139\n",
      "Stage                       428              35.401158 \n",
      "====================== Duplicated rows ======================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Brand</th>\n",
       "      <th>Founded</th>\n",
       "      <th>HeadQuarter</th>\n",
       "      <th>Sector</th>\n",
       "      <th>What_it_does</th>\n",
       "      <th>Founders</th>\n",
       "      <th>Investor</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Curefoods</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Food &amp; Beverages</td>\n",
       "      <td>Healthy &amp; nutritious foods and cold pressed ju...</td>\n",
       "      <td>Ankit Nagori</td>\n",
       "      <td>Iron Pillar, Nordstar, Binny Bansal</td>\n",
       "      <td>$13000000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Bewakoof</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Apparel &amp; Fashion</td>\n",
       "      <td>Bewakoof is a lifestyle fashion brand that mak...</td>\n",
       "      <td>Prabhkiran Singh</td>\n",
       "      <td>InvestCorp</td>\n",
       "      <td>$8000000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>FanPlay</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Computer Games</td>\n",
       "      <td>Computer Games</td>\n",
       "      <td>A real money game app specializing in trivia g...</td>\n",
       "      <td>YC W21</td>\n",
       "      <td>Pritesh Kumar, Bharat Gupta</td>\n",
       "      <td>Upsparks</td>\n",
       "      <td>$1200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Advantage Club</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>HRTech</td>\n",
       "      <td>Advantage Club is India's largest employee eng...</td>\n",
       "      <td>Sourabh Deorah, Smiti Bhatt Deorah</td>\n",
       "      <td>Y Combinator, Broom Ventures, Kunal Shah</td>\n",
       "      <td>$1700000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Ruptok</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Ruptok fintech Pvt. Ltd. is an online gold loa...</td>\n",
       "      <td>Ankur Gupta</td>\n",
       "      <td>Eclear Leasing</td>\n",
       "      <td>$1000000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>Trinkerr</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Capital Markets</td>\n",
       "      <td>Trinkerr is India's first social trading platf...</td>\n",
       "      <td>Manvendra Singh, Gaurav Agarwal</td>\n",
       "      <td>Accel India</td>\n",
       "      <td>$6600000</td>\n",
       "      <td>Series A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Zorro</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>Gurugram</td>\n",
       "      <td>Social network</td>\n",
       "      <td>Pseudonymous social network platform</td>\n",
       "      <td>Jasveer Singh, Abhishek Asthana, Deepak Kumar</td>\n",
       "      <td>Vijay Shekhar Sharma, Ritesh Agarwal, Ankiti Bose</td>\n",
       "      <td>$32000000</td>\n",
       "      <td>Seed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Ultraviolette</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>Create and Inspire the future of sustainable u...</td>\n",
       "      <td>Subramaniam Narayan, Niraj Rajmohan</td>\n",
       "      <td>TVS Motor, Zoho</td>\n",
       "      <td>$150000000</td>\n",
       "      <td>Series C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>NephroPlus</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Hospital &amp; Health Care</td>\n",
       "      <td>A vision and passion of redefining healthcare ...</td>\n",
       "      <td>Vikram Vuppala</td>\n",
       "      <td>IIFL Asset Management</td>\n",
       "      <td>$24000000</td>\n",
       "      <td>Series E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Unremot</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Information Technology &amp; Services</td>\n",
       "      <td>Unremot is a personal office for consultants!</td>\n",
       "      <td>Shiju Radhakrishnan</td>\n",
       "      <td>Inflection Point Ventures</td>\n",
       "      <td>$700000</td>\n",
       "      <td>Seed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>FanAnywhere</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Celebrity NFT platform</td>\n",
       "      <td>Varun Chaudhary, Amit Kumar</td>\n",
       "      <td>Oasis Capital, Scorpio VC, DeltaHub Capital</td>\n",
       "      <td>$Undisclosed</td>\n",
       "      <td>Seed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>PingoLearn</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>Pune</td>\n",
       "      <td>E-learning</td>\n",
       "      <td>PingoLearn offers language learning courses wi...</td>\n",
       "      <td>Mohit Menghani, Shubham Maheshwari</td>\n",
       "      <td>Titan Capital, Haresh Chawla, AngelList Syndicate</td>\n",
       "      <td>$200000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>Spry</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Music</td>\n",
       "      <td>THE BEST ROYALTY-FREE MUSIC TO CREATE TRENDING...</td>\n",
       "      <td>Gaurav Dagaonkar, Meghna Mittal</td>\n",
       "      <td>9Unicorns, Ashneer Grover</td>\n",
       "      <td>$1500000</td>\n",
       "      <td>Seed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Enmovil</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Information Technology &amp; Services</td>\n",
       "      <td>Enmovil delivers a Business Intelligence Platf...</td>\n",
       "      <td>Ravi Bulusu, Nanda Kishore, Venkat Moganty</td>\n",
       "      <td>Anicut Angel Fund</td>\n",
       "      <td>$1300000</td>\n",
       "      <td>Pre-series A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>ASQI Advisors</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Bringing Blockchain technology intro mainstrea...</td>\n",
       "      <td>Swapnil Pawar</td>\n",
       "      <td>Founders Room Capital</td>\n",
       "      <td>$1000000</td>\n",
       "      <td>Pre-series A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>Insurance Samadhan</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Insurance</td>\n",
       "      <td>The insurance industry will help in representa...</td>\n",
       "      <td>Deepak Bhuvenshwari Uniyal</td>\n",
       "      <td>9Unicorns, ZNL</td>\n",
       "      <td>$725000</td>\n",
       "      <td>Pre-series A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>Evenflow Brands</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Consumer Goods</td>\n",
       "      <td>Identify and partner with the upcoming eCommer...</td>\n",
       "      <td>Utsav Agarwal, Pulkit Chhabra</td>\n",
       "      <td>None</td>\n",
       "      <td>$500000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>MasterChow</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Food &amp; Beverages</td>\n",
       "      <td>Hauz Khas</td>\n",
       "      <td>A ready-to-cook Asian cuisine brand</td>\n",
       "      <td>Vidur Kataria, Sidhanth Madan</td>\n",
       "      <td>WEH Ventures</td>\n",
       "      <td>$461000</td>\n",
       "      <td>Seed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>Fullife Healthcare</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Pharmaceuticals\\t#REF!</td>\n",
       "      <td>Primary Business is Development and Manufactur...</td>\n",
       "      <td>Varun Khanna</td>\n",
       "      <td>Morgan Stanley Private Equity Asia</td>\n",
       "      <td>$22000000</td>\n",
       "      <td>Series C</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Company_Brand  Founded             HeadQuarter  \\\n",
       "107           Curefoods   2020.0               Bangalore   \n",
       "109            Bewakoof   2012.0                  Mumbai   \n",
       "111             FanPlay   2020.0          Computer Games   \n",
       "117      Advantage Club   2014.0                  Mumbai   \n",
       "119              Ruptok   2020.0               New Delhi   \n",
       "243            Trinkerr   2021.0               Bangalore   \n",
       "244               Zorro   2021.0                Gurugram   \n",
       "245       Ultraviolette   2021.0               Bangalore   \n",
       "246          NephroPlus   2009.0               Hyderabad   \n",
       "247             Unremot   2020.0               Bangalore   \n",
       "248         FanAnywhere   2021.0               Bangalore   \n",
       "249          PingoLearn   2021.0                    Pune   \n",
       "250                Spry   2021.0                  Mumbai   \n",
       "251             Enmovil   2015.0               Hyderabad   \n",
       "252       ASQI Advisors   2019.0                  Mumbai   \n",
       "253  Insurance Samadhan   2018.0               New Delhi   \n",
       "254     Evenflow Brands   2020.0                  Mumbai   \n",
       "255          MasterChow   2020.0        Food & Beverages   \n",
       "256  Fullife Healthcare   2009.0  Pharmaceuticals\\t#REF!   \n",
       "\n",
       "                                                Sector  \\\n",
       "107                                   Food & Beverages   \n",
       "109                                  Apparel & Fashion   \n",
       "111                                     Computer Games   \n",
       "117                                             HRTech   \n",
       "119                                            FinTech   \n",
       "243                                    Capital Markets   \n",
       "244                                     Social network   \n",
       "245                                         Automotive   \n",
       "246                             Hospital & Health Care   \n",
       "247                  Information Technology & Services   \n",
       "248                                 Financial Services   \n",
       "249                                         E-learning   \n",
       "250                                              Music   \n",
       "251                  Information Technology & Services   \n",
       "252                                 Financial Services   \n",
       "253                                          Insurance   \n",
       "254                                     Consumer Goods   \n",
       "255                                          Hauz Khas   \n",
       "256  Primary Business is Development and Manufactur...   \n",
       "\n",
       "                                          What_it_does  \\\n",
       "107  Healthy & nutritious foods and cold pressed ju...   \n",
       "109  Bewakoof is a lifestyle fashion brand that mak...   \n",
       "111  A real money game app specializing in trivia g...   \n",
       "117  Advantage Club is India's largest employee eng...   \n",
       "119  Ruptok fintech Pvt. Ltd. is an online gold loa...   \n",
       "243  Trinkerr is India's first social trading platf...   \n",
       "244               Pseudonymous social network platform   \n",
       "245  Create and Inspire the future of sustainable u...   \n",
       "246  A vision and passion of redefining healthcare ...   \n",
       "247      Unremot is a personal office for consultants!   \n",
       "248                             Celebrity NFT platform   \n",
       "249  PingoLearn offers language learning courses wi...   \n",
       "250  THE BEST ROYALTY-FREE MUSIC TO CREATE TRENDING...   \n",
       "251  Enmovil delivers a Business Intelligence Platf...   \n",
       "252  Bringing Blockchain technology intro mainstrea...   \n",
       "253  The insurance industry will help in representa...   \n",
       "254  Identify and partner with the upcoming eCommer...   \n",
       "255                A ready-to-cook Asian cuisine brand   \n",
       "256                                       Varun Khanna   \n",
       "\n",
       "                                          Founders  \\\n",
       "107                                   Ankit Nagori   \n",
       "109                               Prabhkiran Singh   \n",
       "111                                         YC W21   \n",
       "117             Sourabh Deorah, Smiti Bhatt Deorah   \n",
       "119                                    Ankur Gupta   \n",
       "243                Manvendra Singh, Gaurav Agarwal   \n",
       "244  Jasveer Singh, Abhishek Asthana, Deepak Kumar   \n",
       "245            Subramaniam Narayan, Niraj Rajmohan   \n",
       "246                                 Vikram Vuppala   \n",
       "247                            Shiju Radhakrishnan   \n",
       "248                    Varun Chaudhary, Amit Kumar   \n",
       "249             Mohit Menghani, Shubham Maheshwari   \n",
       "250                Gaurav Dagaonkar, Meghna Mittal   \n",
       "251     Ravi Bulusu, Nanda Kishore, Venkat Moganty   \n",
       "252                                  Swapnil Pawar   \n",
       "253                     Deepak Bhuvenshwari Uniyal   \n",
       "254                  Utsav Agarwal, Pulkit Chhabra   \n",
       "255                  Vidur Kataria, Sidhanth Madan   \n",
       "256             Morgan Stanley Private Equity Asia   \n",
       "\n",
       "                                              Investor        Amount  \\\n",
       "107                Iron Pillar, Nordstar, Binny Bansal     $13000000   \n",
       "109                                         InvestCorp      $8000000   \n",
       "111                        Pritesh Kumar, Bharat Gupta      Upsparks   \n",
       "117           Y Combinator, Broom Ventures, Kunal Shah      $1700000   \n",
       "119                                     Eclear Leasing      $1000000   \n",
       "243                                        Accel India      $6600000   \n",
       "244  Vijay Shekhar Sharma, Ritesh Agarwal, Ankiti Bose     $32000000   \n",
       "245                                    TVS Motor, Zoho    $150000000   \n",
       "246                              IIFL Asset Management     $24000000   \n",
       "247                          Inflection Point Ventures       $700000   \n",
       "248        Oasis Capital, Scorpio VC, DeltaHub Capital  $Undisclosed   \n",
       "249  Titan Capital, Haresh Chawla, AngelList Syndicate       $200000   \n",
       "250                          9Unicorns, Ashneer Grover      $1500000   \n",
       "251                                  Anicut Angel Fund      $1300000   \n",
       "252                              Founders Room Capital      $1000000   \n",
       "253                                     9Unicorns, ZNL       $725000   \n",
       "254                                               None       $500000   \n",
       "255                                       WEH Ventures       $461000   \n",
       "256                                          $22000000      Series C   \n",
       "\n",
       "            Stage  \n",
       "107          None  \n",
       "109          None  \n",
       "111      $1200000  \n",
       "117          None  \n",
       "119          None  \n",
       "243      Series A  \n",
       "244          Seed  \n",
       "245      Series C  \n",
       "246      Series E  \n",
       "247          Seed  \n",
       "248          Seed  \n",
       "249          None  \n",
       "250          Seed  \n",
       "251  Pre-series A  \n",
       "252  Pre-series A  \n",
       "253  Pre-series A  \n",
       "254          None  \n",
       "255          Seed  \n",
       "256          None  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check characteristics of dataframe\n",
    "print(df_2021.info(), \"\\n====================== Null Value Percentage ======================\")\n",
    "# Check for null values\n",
    "print(pd.DataFrame({\"null_value_count\": df_2021.isna().sum(), \"percentage_null_value\": df_2021.isna().mean().mul(100) }), \"\\n====================== Duplicated rows ======================\")\n",
    "# Check for duplicates\n",
    "df_2021.loc[df_2021.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicated rows\n",
    "df_2021.drop_duplicates(keep = \"first\", inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2018 Dataset Exploration and Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Round/Series</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Location</th>\n",
       "      <th>About Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TheCollegeFever</td>\n",
       "      <td>Brand Marketing, Event Promotion, Marketing, S...</td>\n",
       "      <td>Seed</td>\n",
       "      <td>250000</td>\n",
       "      <td>Bangalore, Karnataka, India</td>\n",
       "      <td>TheCollegeFever is a hub for fun, fiesta and f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Happy Cow Dairy</td>\n",
       "      <td>Agriculture, Farming</td>\n",
       "      <td>Seed</td>\n",
       "      <td>₹40,000,000</td>\n",
       "      <td>Mumbai, Maharashtra, India</td>\n",
       "      <td>A startup which aggregates milk from dairy far...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MyLoanCare</td>\n",
       "      <td>Credit, Financial Services, Lending, Marketplace</td>\n",
       "      <td>Series A</td>\n",
       "      <td>₹65,000,000</td>\n",
       "      <td>Gurgaon, Haryana, India</td>\n",
       "      <td>Leading Online Loans Marketplace in India</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Company Name                                           Industry  \\\n",
       "0  TheCollegeFever  Brand Marketing, Event Promotion, Marketing, S...   \n",
       "1  Happy Cow Dairy                               Agriculture, Farming   \n",
       "2       MyLoanCare   Credit, Financial Services, Lending, Marketplace   \n",
       "\n",
       "  Round/Series       Amount                     Location  \\\n",
       "0         Seed       250000  Bangalore, Karnataka, India   \n",
       "1         Seed  ₹40,000,000   Mumbai, Maharashtra, India   \n",
       "2     Series A  ₹65,000,000      Gurgaon, Haryana, India   \n",
       "\n",
       "                                       About Company  \n",
       "0  TheCollegeFever is a hub for fun, fiesta and f...  \n",
       "1  A startup which aggregates milk from dairy far...  \n",
       "2          Leading Online Loans Marketplace in India  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview dataframe\n",
    "df_2018.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 526 entries, 0 to 525\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Company Name   526 non-null    object\n",
      " 1   Industry       526 non-null    object\n",
      " 2   Round/Series   526 non-null    object\n",
      " 3   Amount         526 non-null    object\n",
      " 4   Location       526 non-null    object\n",
      " 5   About Company  526 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 24.8+ KB\n",
      "None \n",
      "====================== Null Value Percentage ======================\n",
      "               null_value_count  percentage_null_value\n",
      "Company Name                  0                    0.0\n",
      "Industry                      0                    0.0\n",
      "Round/Series                  0                    0.0\n",
      "Amount                        0                    0.0\n",
      "Location                      0                    0.0\n",
      "About Company                 0                    0.0 \n",
      "====================== Duplicated rows ======================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Round/Series</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Location</th>\n",
       "      <th>About Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>TheCollegeFever</td>\n",
       "      <td>Brand Marketing, Event Promotion, Marketing, S...</td>\n",
       "      <td>Seed</td>\n",
       "      <td>250000</td>\n",
       "      <td>Bangalore, Karnataka, India</td>\n",
       "      <td>TheCollegeFever is a hub for fun, fiesta and f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Company Name                                           Industry  \\\n",
       "348  TheCollegeFever  Brand Marketing, Event Promotion, Marketing, S...   \n",
       "\n",
       "    Round/Series  Amount                     Location  \\\n",
       "348         Seed  250000  Bangalore, Karnataka, India   \n",
       "\n",
       "                                         About Company  \n",
       "348  TheCollegeFever is a hub for fun, fiesta and f...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check characteristics of dataframe\n",
    "print(df_2018.info(), \"\\n====================== Null Value Percentage ======================\")\n",
    "# Check for null values\n",
    "print(pd.DataFrame({\"null_value_count\": df_2018.isna().sum(), \"percentage_null_value\": df_2018.isna().mean().mul(100) }), \"\\n====================== Duplicated rows ======================\")\n",
    "# Check for duplicates\n",
    "df_2018.loc[df_2018.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicated rows from DataFrame\n",
    "df_2018.drop_duplicates(keep = \"first\", inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2019 Dataset Exploration and Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company/Brand</th>\n",
       "      <th>Founded</th>\n",
       "      <th>HeadQuarter</th>\n",
       "      <th>Sector</th>\n",
       "      <th>What it does</th>\n",
       "      <th>Founders</th>\n",
       "      <th>Investor</th>\n",
       "      <th>Amount($)</th>\n",
       "      <th>Stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bombay Shaving</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ecommerce</td>\n",
       "      <td>Provides a range of male grooming products</td>\n",
       "      <td>Shantanu Deshpande</td>\n",
       "      <td>Sixth Sense Ventures</td>\n",
       "      <td>$6,300,000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ruangguru</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Edtech</td>\n",
       "      <td>A learning platform that provides topic-based ...</td>\n",
       "      <td>Adamas Belva Syah Devara, Iman Usman.</td>\n",
       "      <td>General Atlantic</td>\n",
       "      <td>$150,000,000</td>\n",
       "      <td>Series C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eduisfun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Edtech</td>\n",
       "      <td>It aims to make learning fun via games.</td>\n",
       "      <td>Jatin Solanki</td>\n",
       "      <td>Deepak Parekh, Amitabh Bachchan, Piyush Pandey</td>\n",
       "      <td>$28,000,000</td>\n",
       "      <td>Fresh funding</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company/Brand  Founded HeadQuarter     Sector  \\\n",
       "0  Bombay Shaving      NaN         NaN  Ecommerce   \n",
       "1       Ruangguru   2014.0      Mumbai     Edtech   \n",
       "2        Eduisfun      NaN      Mumbai     Edtech   \n",
       "\n",
       "                                        What it does  \\\n",
       "0         Provides a range of male grooming products   \n",
       "1  A learning platform that provides topic-based ...   \n",
       "2            It aims to make learning fun via games.   \n",
       "\n",
       "                                Founders  \\\n",
       "0                     Shantanu Deshpande   \n",
       "1  Adamas Belva Syah Devara, Iman Usman.   \n",
       "2                          Jatin Solanki   \n",
       "\n",
       "                                         Investor     Amount($)          Stage  \n",
       "0                            Sixth Sense Ventures    $6,300,000            NaN  \n",
       "1                                General Atlantic  $150,000,000       Series C  \n",
       "2  Deepak Parekh, Amitabh Bachchan, Piyush Pandey   $28,000,000  Fresh funding  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview dataframe\n",
    "df_2019.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 89 entries, 0 to 88\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Company/Brand  89 non-null     object \n",
      " 1   Founded        60 non-null     float64\n",
      " 2   HeadQuarter    70 non-null     object \n",
      " 3   Sector         84 non-null     object \n",
      " 4   What it does   89 non-null     object \n",
      " 5   Founders       86 non-null     object \n",
      " 6   Investor       89 non-null     object \n",
      " 7   Amount($)      89 non-null     object \n",
      " 8   Stage          43 non-null     object \n",
      "dtypes: float64(1), object(8)\n",
      "memory usage: 6.4+ KB\n",
      "None \n",
      "====================== Null Value Percentage ======================\n",
      "               null_value_count  percentage_null_value\n",
      "Company/Brand                 0               0.000000\n",
      "Founded                      29              32.584270\n",
      "HeadQuarter                  19              21.348315\n",
      "Sector                        5               5.617978\n",
      "What it does                  0               0.000000\n",
      "Founders                      3               3.370787\n",
      "Investor                      0               0.000000\n",
      "Amount($)                     0               0.000000\n",
      "Stage                        46              51.685393 \n",
      "====================== Duplicated rows ======================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company/Brand</th>\n",
       "      <th>Founded</th>\n",
       "      <th>HeadQuarter</th>\n",
       "      <th>Sector</th>\n",
       "      <th>What it does</th>\n",
       "      <th>Founders</th>\n",
       "      <th>Investor</th>\n",
       "      <th>Amount($)</th>\n",
       "      <th>Stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Company/Brand, Founded, HeadQuarter, Sector, What it does, Founders, Investor, Amount($), Stage]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check characteristics of dataframe\n",
    "print(df_2019.info(), \"\\n====================== Null Value Percentage ======================\")\n",
    "# Check for null values\n",
    "print(pd.DataFrame({\"null_value_count\": df_2019.isna().sum(), \"percentage_null_value\": df_2019.isna().mean().mul(100) }), \"\\n====================== Duplicated rows ======================\")\n",
    "# Check for duplicate\n",
    "df_2019.loc[df_2019.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add year_funded column to each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Brand</th>\n",
       "      <th>Founded</th>\n",
       "      <th>HeadQuarter</th>\n",
       "      <th>Sector</th>\n",
       "      <th>What_it_does</th>\n",
       "      <th>Founders</th>\n",
       "      <th>Investor</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Stage</th>\n",
       "      <th>Year_Funded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aqgromalin</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>AgriTech</td>\n",
       "      <td>Cultivating Ideas for Profit</td>\n",
       "      <td>Prasanna Manogaran, Bharani C L</td>\n",
       "      <td>Angel investors</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Krayonnz</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>EdTech</td>\n",
       "      <td>An academy-guardian-scholar centric ecosystem ...</td>\n",
       "      <td>Saurabh Dixit, Gurudutt Upadhyay</td>\n",
       "      <td>GSF Accelerator</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>Pre-seed</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PadCare Labs</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Hygiene management</td>\n",
       "      <td>Converting bio-hazardous waste to harmless waste</td>\n",
       "      <td>Ajinkya Dhariya</td>\n",
       "      <td>Venture Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pre-seed</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Company_Brand  Founded HeadQuarter              Sector  \\\n",
       "0    Aqgromalin   2019.0     Chennai            AgriTech   \n",
       "1      Krayonnz   2019.0   Bangalore              EdTech   \n",
       "2  PadCare Labs   2018.0        Pune  Hygiene management   \n",
       "\n",
       "                                        What_it_does  \\\n",
       "0                       Cultivating Ideas for Profit   \n",
       "1  An academy-guardian-scholar centric ecosystem ...   \n",
       "2   Converting bio-hazardous waste to harmless waste   \n",
       "\n",
       "                           Founders         Investor    Amount     Stage  \\\n",
       "0   Prasanna Manogaran, Bharani C L  Angel investors  200000.0      None   \n",
       "1  Saurabh Dixit, Gurudutt Upadhyay  GSF Accelerator  100000.0  Pre-seed   \n",
       "2                   Ajinkya Dhariya   Venture Center       NaN  Pre-seed   \n",
       "\n",
       "   Year_Funded  \n",
       "0         2020  \n",
       "1         2020  \n",
       "2         2020  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add year column to dataframe\n",
    "df_2020[\"Year_Funded\"] = 2020\n",
    "df_2021[\"Year_Funded\"] = 2021\n",
    "df_2019[\"Year_Funded\"] = 2019\n",
    "df_2018[\"Year_Funded\"] = 2018\n",
    "\n",
    "# Preview dataframe\n",
    "df_2020.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Establish uniformity in column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "df_2019.rename(columns={'Company/Brand':'Company_Brand','Amount($)':'Amount', 'What it does': 'What_it_does'}, inplace=True)\n",
    "\n",
    "df_2018.rename(columns={'Company Name':'Company_Brand','Industry':'Sector','Round/Series':'Stage','Location':'HeadQuarter','About Company':'What_it_does'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['company_brand', 'founded', 'headquarter', 'sector', 'what_it_does',\n",
       "       'founders', 'investor', 'amount', 'stage', 'year_funded'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rename_column(df):\n",
    "    \"\"\"\n",
    "    This function takes in a dataframe and renames the column names to lower case\n",
    "    \"\"\"\n",
    "    df.columns = [col_name.lower() for col_name in df.columns]\n",
    "    return df\n",
    "\n",
    "# Apply function to DataFrames\n",
    "df_2018.pipe(rename_column)\n",
    "df_2019.pipe(rename_column)\n",
    "df_2020.pipe(rename_column)\n",
    "df_2021.pipe(rename_column)\n",
    "\n",
    "# Preview column names\n",
    "df_2021.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify if column name is standardised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['company_brand', 'sector', 'stage', 'amount', 'headquarter',\n",
      "       'what_it_does', 'year_funded'],\n",
      "      dtype='object')\n",
      "Index(['company_brand', 'founded', 'headquarter', 'sector', 'what_it_does',\n",
      "       'founders', 'investor', 'amount', 'stage', 'year_funded'],\n",
      "      dtype='object')\n",
      "Index(['company_brand', 'founded', 'headquarter', 'sector', 'what_it_does',\n",
      "       'founders', 'investor', 'amount', 'stage', 'year_funded'],\n",
      "      dtype='object')\n",
      "Index(['company_brand', 'founded', 'headquarter', 'sector', 'what_it_does',\n",
      "       'founders', 'investor', 'amount', 'stage', 'year_funded'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Compare if column names are uniform\n",
    "print(df_2018.columns)\n",
    "print(df_2019.columns)\n",
    "print(df_2020.columns)\n",
    "print(df_2021.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_brand</th>\n",
       "      <th>founded</th>\n",
       "      <th>headquarter</th>\n",
       "      <th>sector</th>\n",
       "      <th>what_it_does</th>\n",
       "      <th>founders</th>\n",
       "      <th>investor</th>\n",
       "      <th>amount</th>\n",
       "      <th>stage</th>\n",
       "      <th>year_funded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aqgromalin</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>AgriTech</td>\n",
       "      <td>Cultivating Ideas for Profit</td>\n",
       "      <td>Prasanna Manogaran, Bharani C L</td>\n",
       "      <td>Angel investors</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Krayonnz</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>EdTech</td>\n",
       "      <td>An academy-guardian-scholar centric ecosystem ...</td>\n",
       "      <td>Saurabh Dixit, Gurudutt Upadhyay</td>\n",
       "      <td>GSF Accelerator</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>Pre-seed</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PadCare Labs</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Hygiene management</td>\n",
       "      <td>Converting bio-hazardous waste to harmless waste</td>\n",
       "      <td>Ajinkya Dhariya</td>\n",
       "      <td>Venture Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pre-seed</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company_brand  founded headquarter              sector  \\\n",
       "0    Aqgromalin   2019.0     Chennai            AgriTech   \n",
       "1      Krayonnz   2019.0   Bangalore              EdTech   \n",
       "2  PadCare Labs   2018.0        Pune  Hygiene management   \n",
       "\n",
       "                                        what_it_does  \\\n",
       "0                       Cultivating Ideas for Profit   \n",
       "1  An academy-guardian-scholar centric ecosystem ...   \n",
       "2   Converting bio-hazardous waste to harmless waste   \n",
       "\n",
       "                           founders         investor    amount     stage  \\\n",
       "0   Prasanna Manogaran, Bharani C L  Angel investors  200000.0      None   \n",
       "1  Saurabh Dixit, Gurudutt Upadhyay  GSF Accelerator  100000.0  Pre-seed   \n",
       "2                   Ajinkya Dhariya   Venture Center       NaN  Pre-seed   \n",
       "\n",
       "   year_funded  \n",
       "0         2020  \n",
       "1         2020  \n",
       "2         2020  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all four datasets into a single dataframe\n",
    "df_combined = pd.concat([df_2020, df_2021, df_2018, df_2019], axis = 0)\n",
    "# Reset index to avoid duplication of index\n",
    "df_combined.reset_index(drop = True, inplace = True)\n",
    "# Preview combined dataframe\n",
    "df_combined.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2856 entries, 0 to 2855\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   company_brand  2856 non-null   object \n",
      " 1   founded        2088 non-null   float64\n",
      " 2   headquarter    2742 non-null   object \n",
      " 3   sector         2838 non-null   object \n",
      " 4   what_it_does   2856 non-null   object \n",
      " 5   founders       2312 non-null   object \n",
      " 6   investor       2232 non-null   object \n",
      " 7   amount         2600 non-null   object \n",
      " 8   stage          1927 non-null   object \n",
      " 9   year_funded    2856 non-null   int64  \n",
      "dtypes: float64(1), int64(1), object(8)\n",
      "memory usage: 223.2+ KB\n",
      "None \n",
      "====================== Null Value Count / Percentage ======================\n",
      "               null_value_count  percentage_null_value\n",
      "company_brand                 0               0.000000\n",
      "founded                     768              26.890756\n",
      "headquarter                 114               3.991597\n",
      "sector                       18               0.630252\n",
      "what_it_does                  0               0.000000\n",
      "founders                    544              19.047619\n",
      "investor                    624              21.848739\n",
      "amount                      256               8.963585\n",
      "stage                       929              32.528011\n",
      "year_funded                   0               0.000000 \n",
      "====================== Duplicated rows ======================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_brand</th>\n",
       "      <th>founded</th>\n",
       "      <th>headquarter</th>\n",
       "      <th>sector</th>\n",
       "      <th>what_it_does</th>\n",
       "      <th>founders</th>\n",
       "      <th>investor</th>\n",
       "      <th>amount</th>\n",
       "      <th>stage</th>\n",
       "      <th>year_funded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [company_brand, founded, headquarter, sector, what_it_does, founders, investor, amount, stage, year_funded]\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check characteristics of dataframe\n",
    "print(df_combined.info(), \"\\n====================== Null Value Count / Percentage ======================\")\n",
    "# Check for null values\n",
    "print(pd.DataFrame({\"null_value_count\": df_combined.isna().sum(), \"percentage_null_value\": df_combined.isna().mean().mul(100) }), \"\\n====================== Duplicated rows ======================\")\n",
    "# Check for duplicated rows\n",
    "df_combined.loc[df_combined.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Cleaning\n",
    "### `Column: year_funded`\n",
    "\n",
    "Change datatype of year_funded column from integer to datatime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company_brand            object\n",
       "founded                 float64\n",
       "headquarter              object\n",
       "sector                   object\n",
       "what_it_does             object\n",
       "founders                 object\n",
       "investor                 object\n",
       "amount                   object\n",
       "stage                    object\n",
       "year_funded      datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def year_to_datetime(column):\n",
    "    \"\"\"\n",
    "    Converts year to datetime format\n",
    "    \"\"\"\n",
    "    # Convert year to datetime format\n",
    "    return pd.to_datetime(column, format = \"%Y\")\n",
    "\n",
    "# Apply function to column\n",
    "df_combined[\"year_funded\"] = df_combined[\"year_funded\"].apply(year_to_datetime)\n",
    "# Confirm comverted datatype\n",
    "df_combined.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Column: amount`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([200000.0, 100000.0, nan, 400000.0, 340000.0, 600000.0, 45000000.0,\n",
       "       1000000.0, 2000000.0, 1200000.0, 660000000.0, 120000.0, 7500000.0,\n",
       "       5000000.0, 500000.0, 3000000.0, 10000000.0, 145000000.0,\n",
       "       100000000.0, 21000000.0, 4000000.0, 20000000.0, 560000.0, 275000.0,\n",
       "       4500000.0, 15000000.0, 390000000.0, 7000000.0, 5100000.0,\n",
       "       700000000.0, 2300000.0, 700000.0, 19000000.0, 9000000.0,\n",
       "       40000000.0, 750000.0, 1500000.0, 7800000.0, 50000000.0, 80000000.0],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview unique entries in the amount column\n",
    "df_combined[\"amount\"].unique()[:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amount, Stage, and investor columns have some of their values interchanged and need to be cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Pre series A1', 'Series E2', 'Pre series A', 'Seed Round',\n",
       "       'Bridge Round', 'Pre seed round', 'Pre series B', 'Pre series C',\n",
       "       'Seed Investment', 'Series D1', 'Mid series', 'Series C, D',\n",
       "       'Seed funding', '$1200000', 'Seed+', 'Series F2', 'Series A+',\n",
       "       'Series G', 'Series B3', 'PE', 'Series F1', 'Pre-series A1',\n",
       "       '$300000', 'Early seed', '$6000000', '$1000000', 'Seies A',\n",
       "       'Series A2', 'Series I', 'Angel', 'Private Equity',\n",
       "       'Venture - Series Unknown'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preview unique entries in the stage column\n",
    "df_combined[\"stage\"].unique()[30:-15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_brand</th>\n",
       "      <th>founded</th>\n",
       "      <th>headquarter</th>\n",
       "      <th>sector</th>\n",
       "      <th>what_it_does</th>\n",
       "      <th>founders</th>\n",
       "      <th>investor</th>\n",
       "      <th>amount</th>\n",
       "      <th>stage</th>\n",
       "      <th>year_funded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>FanPlay</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Computer Games</td>\n",
       "      <td>Computer Games</td>\n",
       "      <td>A real money game app specializing in trivia g...</td>\n",
       "      <td>YC W21</td>\n",
       "      <td>Pritesh Kumar, Bharat Gupta</td>\n",
       "      <td>Upsparks</td>\n",
       "      <td>$1200000</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     company_brand  founded     headquarter          sector  \\\n",
       "1150       FanPlay   2020.0  Computer Games  Computer Games   \n",
       "\n",
       "                                           what_it_does founders  \\\n",
       "1150  A real money game app specializing in trivia g...   YC W21   \n",
       "\n",
       "                         investor    amount     stage year_funded  \n",
       "1150  Pritesh Kumar, Bharat Gupta  Upsparks  $1200000  2021-01-01  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.loc[df_combined[\"stage\"] == \"$1200000\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put values in their appropriate columns\n",
    "df_combined.at[1710, \"amount\"], df_combined.at[1710, \"stage\"] = 1000000, np.NAN\n",
    "df_combined.at[1571, \"amount\"], df_combined.at[1571, \"stage\"] = 300000, np.NAN\n",
    "df_combined.at[1584, \"amount\"], df_combined.at[1584, \"stage\"] = 300000, np.NAN\n",
    "df_combined.at[1150, \"amount\"], df_combined.at[1150, \"stage\"] = 1200000, np.NAN\n",
    "df_combined.at[1707, \"amount\"], df_combined.at[1707, \"stage\"] = 6000000, np.NAN\n",
    "df_combined.at[1289, \"amount\"], df_combined.at[1289, \"stage\"], df_combined.at[1289, \"investor\"] = 22000000, \"Series C\", np.NAN\n",
    "df_combined.at[1290, \"amount\"], df_combined.at[1290, \"stage\"], df_combined.at[1290, \"investor\"] = 5000000, \"Seed\", np.NAN\n",
    "df_combined.at[2181, \"amount\"], df_combined.at[2181, \"stage\"], df_combined.at[2181, \"investor\"] = 1000000, \"Seed\", np.NAN\n",
    "df_combined.at[1578, \"amount\"], df_combined.at[1578, \"stage\"], df_combined.at[1578, \"investor\"] = 1000000, \"Pre-series A\", np.NAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove currency signs, convert INR (₹) to USD ($), and convert datatype to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.00e+05, 1.00e+05,      nan, 4.00e+05, 3.40e+05, 6.00e+05,\n",
       "       4.50e+07, 1.00e+06, 2.00e+06, 1.20e+06, 6.60e+08, 1.20e+05,\n",
       "       7.50e+06, 5.00e+06, 5.00e+05, 3.00e+06, 1.00e+07, 1.45e+08,\n",
       "       1.00e+08, 2.10e+07, 4.00e+06, 2.00e+07, 5.60e+05, 2.75e+05,\n",
       "       4.50e+06, 1.50e+07, 3.90e+08, 7.00e+06, 5.10e+06, 7.00e+08,\n",
       "       2.30e+06, 7.00e+05, 1.90e+07, 9.00e+06, 4.00e+07])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean Amount colum and convert Indian Rupee to USD currency\n",
    "def clean_amount(value):\n",
    "    \"\"\" \n",
    "    Removes \"$\", and \"₹\"  and converts column to float\n",
    "     \"\"\"\n",
    "    try:\n",
    "        value = str(value)\n",
    "        # Remove commas\n",
    "        value = value.replace(\",\", \"\")\n",
    "        # Check if the amount is in INR and convert to USD assuming 1 USD = 70 INR\n",
    "        if \"₹\" in value:\n",
    "            valuet = value.replace(\"₹\", \"\")\n",
    "            return round(float(value) / 70, 2)\n",
    "        # Check if the amount is in USD\n",
    "        elif \"$\" in value:\n",
    "            value = value.replace(\"$\", \"\")\n",
    "            return round(float(value), 2) \n",
    "        # If no currency symbol, assume it's already in USD\n",
    "        else:\n",
    "            return round(float(value), 2)\n",
    "    except ValueError:\n",
    "        # For non-numeric entries, return NaN\n",
    "        return np.NAN\n",
    "\n",
    "# Apply the clean_amount function to the 'amount' column\n",
    "df_combined[\"amount\"] = df_combined[\"amount\"].apply(clean_amount)\n",
    "\n",
    "# Preview dataframe\n",
    "df_combined[\"amount\"].unique()[:35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Column: headquarter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Rajsamand', 'Ranchi', 'Faridabad, Haryana', 'Computer Games',\n",
       "       'Vadodara', 'Food & Beverages', 'Pharmaceuticals\\t#REF!',\n",
       "       'Gurugram\\t#REF!', 'Mohali', 'Powai', 'Ghaziabad', 'Nagpur',\n",
       "       'West Bengal', 'Samsitpur', 'Lucknow', 'Telangana', 'Silvassa',\n",
       "       'Thiruvananthapuram', 'Faridabad', 'Roorkee', 'Ambernath',\n",
       "       'Panchkula', 'Surat', 'Mangalore', 'Telugana', 'Bhubaneswar',\n",
       "       'Kottayam', 'Beijing', 'Panaji', 'Satara', 'Orissia', 'Santra',\n",
       "       'Mountain View, CA', 'Trivandrum', 'Jharkhand', 'Bhilwara',\n",
       "       'Guwahati', 'Online Media\\t#REF!', 'London',\n",
       "       'Information Technology & Services', 'The Nilgiris', 'Gandhinagar',\n",
       "       'Bangalore, Karnataka, India', 'Mumbai, Maharashtra, India'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview unique values in the headquarter column\n",
    "df_combined[\"headquarter\"].unique()[80:-50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "headquarter, sector, and what it does columns have some of their values interchanged and needs to be cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_brand</th>\n",
       "      <th>founded</th>\n",
       "      <th>headquarter</th>\n",
       "      <th>sector</th>\n",
       "      <th>what_it_does</th>\n",
       "      <th>founders</th>\n",
       "      <th>investor</th>\n",
       "      <th>amount</th>\n",
       "      <th>stage</th>\n",
       "      <th>year_funded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>MasterChow</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Food &amp; Beverages</td>\n",
       "      <td>Hauz Khas</td>\n",
       "      <td>A ready-to-cook Asian cuisine brand</td>\n",
       "      <td>Vidur Kataria, Sidhanth Madan</td>\n",
       "      <td>WEH Ventures</td>\n",
       "      <td>461000.0</td>\n",
       "      <td>Seed</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     company_brand  founded       headquarter     sector  \\\n",
       "1288    MasterChow   2020.0  Food & Beverages  Hauz Khas   \n",
       "\n",
       "                             what_it_does                       founders  \\\n",
       "1288  A ready-to-cook Asian cuisine brand  Vidur Kataria, Sidhanth Madan   \n",
       "\n",
       "          investor    amount stage year_funded  \n",
       "1288  WEH Ventures  461000.0  Seed  2021-01-01  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.loc[df_combined[\"headquarter\"] == \"Food & Beverages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put values in their appropriate columns\n",
    "df_combined.at[1288\t, \"headquarter\"], df_combined.at[1288\t, \"sector\"] = \"Hauz Khas\", \"Food & Beverages\"\n",
    "df_combined.at[1289, \"headquarter\"], df_combined.at[1289, \"sector\"], df_combined.at[1289, \"what_it_does\"] = \"None\", \"Pharmaceuticals\", \"None\"\n",
    "df_combined.at[1290, \"what_it_does\"] = df_combined.at[1290, \"sector\"]\n",
    "df_combined.at[1290, \"headquarter\"], df_combined.at[1290, \"sector\"] = \"Gurugram\", \"None\"\n",
    "df_combined.at[2133, \"what_it_does\"] = df_combined.at[2133, \"sector\"]\n",
    "df_combined.at[2133, \"headquarter\"], df_combined.at[2133, \"sector\"] = \"None\", \"Online Media\"\n",
    "df_combined.at[2209, \"headquarter\"], df_combined.at[2209, \"sector\"] = \"Manchester, Greater Manchester\", \"Information Technology & Services\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct spelling mistakes in the headquarter column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column(value):\n",
    "    \"\"\"\n",
    "    Corrects misspelled values, splits string at the comma, and takes the first string\n",
    "    \"\"\"\n",
    "    replacement = {\"New Delhi\": \"Delhi\", \"New New Delhi\": \"Delhi\", \"San Franciscao\": \"San Francisco\", \"San Francisco Bay Area\": \"San Francisco\",\n",
    "                   \"Bangaldesh\": \"Bangladesh\", \"Milano\": \"Milan\", \"Newcastle Upon Tyne\": \"Newcastle\", \"Hyderebad\": \"Hyderabad\", \"Banglore\": \"Bengaluru\",\n",
    "                   \"Bangalore\": \"Bengaluru\", \"Santra\": \"Santa\", \"Orissa\": \"Odisha\", \"Kormangala\": \"Koramangala\", \"Cochin\": \"Kochi\", \"Orissia\": \"Odisha\",\n",
    "                   \"Thiruvananthapuram\": \"Trivandrum\", \"Samsitpur\": \"Samastipur\", \"Telugana\": \"Telangana\", \"Gurgaon\": \"Gurugram\", \"Rajastan\": \"Rajasthan\",\n",
    "                   \"Uttar pradesh\": \"Uttar Pradesh\", \"Ahmadabad\": \"Ahmedabad\"}\n",
    "    \n",
    "    value = str(value)\n",
    "    # Condition ensures function processes non-None values\n",
    "    if value is not None:\n",
    "        for old_value, new_value in replacement.items():\n",
    "            # Split comma separated values and extract the first value\n",
    "            value = value.split(\",\")[0]\n",
    "            # Replace mispelled values with corrected spelled values\n",
    "            value = value.replace(old_value, new_value)\n",
    "        return value\n",
    "\n",
    "# Apply function to column\n",
    "df_combined[\"headquarter\"] = df_combined[\"headquarter\"].apply(clean_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for entries containing only special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [company_brand, founded, headquarter, sector, what_it_does, founders, investor, amount, stage, year_funded]\n",
      "Index: []\n",
      "\n",
      "There is no special character present in the column\n"
     ]
    }
   ],
   "source": [
    "# Regular expression to match strings containing only special characters\n",
    "special_chars = r'^[^\\w\\s]+$'\n",
    "\n",
    "# Filter the DataFrame to include only entries with \"what_it_does\" containing only special characters\n",
    "print(df_combined[df_combined[\"headquarter\"].str.contains(special_chars, na=False)])\n",
    "\n",
    "print(\"\\nThere is no special character present in the column\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview headquarter column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Chennai', 'Bengaluru', 'Pune', 'Delhi', 'Indore', 'Hyderabad',\n",
       "       'Gurugram', 'Belgaum', 'Noida', 'Mumbai', 'Andheri', 'Jaipur',\n",
       "       'Ahmedabad', 'Kolkata', 'Tirunelveli', 'Thane', nan, 'Singapore',\n",
       "       'Gujarat', 'Haryana'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace \"nan\" with np.NAN for it to be recognised as a null value\n",
    "df_combined[\"headquarter\"].replace(\"nan\", np.NAN, inplace = True)\n",
    "df_combined[\"headquarter\"].replace(\"None\", np.NAN, inplace = True)\n",
    "# Preview column\n",
    "df_combined[\"headquarter\"].unique()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorising headquarter based on location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Tamil Nadu', 'Bengaluru', 'Pune', 'Delhi', 'Indore', 'Hyderabad',\n",
       "       'Gurgaon', 'Belgaum', 'Uttar Pradesh', 'Mumbai', 'Maharashtra',\n",
       "       'Jaipur', 'Ahmedabad', 'Kolkata', nan, 'Singapore', 'Anand',\n",
       "       'Haryana', 'Kerala', 'Rajasthan', 'Frisco', 'California',\n",
       "       'Dhingsara', 'New York', 'Patna', 'Paris', 'Plano', 'Sydney',\n",
       "       'Bangladesh', 'London', 'Milan', 'Palmwoods', 'France', 'Bihar',\n",
       "       'Tumkur', 'Newcastle', 'Shanghai', 'Jiaxing', 'Ludhiana',\n",
       "       'Dehradun', 'Tangerang', 'Berlin', 'Seattle', 'Riyadh', 'Seoul',\n",
       "       'Bangkok', 'Chandigarh', 'Warangal', 'Odisha', 'Margão', 'Bhopal',\n",
       "       'Coimbatore', 'Small Towns', 'Rajsamand', 'Ranchi', 'Faridabad',\n",
       "       'Computer Games', 'Vadodara', 'Mohali', 'Nagpur', 'West Bengal',\n",
       "       'Silvassa', 'Roorkee', 'Ambernath', 'Panchkula', 'Surat',\n",
       "       'Mangalore', 'Bhubaneswar', 'Kottayam', 'Beijing', 'Panaji',\n",
       "       'Satara', 'Santa', 'Jharkhand', 'Bhilwara', 'Guwahati',\n",
       "       'Manchester', 'The Nilgiris', 'Gandhinagar', 'India', 'Hubli',\n",
       "       'Kota', 'Alwar', 'Guntur'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def city_names(value):\n",
    "    \"\"\"\n",
    "    Replaces sub cities with their major cities\n",
    "    \"\"\"\n",
    "    cities = {\"Bengaluru\": [\"Bengaluru City\", \"Koramangala\"], \"Delhi\": [\"Kalkaji\", \"Hauz Khas\", \"Azadpur\"], \"California\": [\"San Francisco\", \"Mountain View\", \"San Ramon\", \"Irvine\"],\n",
    "            \"Tamil Nadu\": [\"Chennai\", \"Tirunelveli\", \"Guindy\", \"Mylapore\", \"Kalpakkam\"], \"Maharashtra\": [\"Andheri\", \"Thane\", \"Worli\"],\n",
    "            \"Uttar Pradesh\": [\"Ghaziabad\", \"Uttar\", \"Lucknow\", \"Kanpur\", \"Noida\"], \"Rajasthan\": [\"Alwar\", \"Rajasthan\"], \"Mumbai\": [\"Powai\", \"Andheri\"],\n",
    "            \"Kerala\": [\"Kochi\", \"Alleppey\", \"Kannur\", \"Ernakulam\", \"Trivandrum\"], \"Margão\": [\"Goa\"], \"Anand\": [\"Gujarat\"], \"Hyderabad\": [\"Telangana\"],\n",
    "            \"Bihar\": [\"Samastipur\", \"Bihar\"], \"Rajasthan\": [\"Jodhpur\"], \"Gurgaon\": [\"Gurugram\"]}\n",
    "    \n",
    "    # Put headquarter into categories\n",
    "    for major_city, sub_city in cities.items():\n",
    "        if value in sub_city:\n",
    "            value = major_city\n",
    "    return value\n",
    "\n",
    "# Apply function to column\n",
    "df_combined[\"headquarter\"] = df_combined[\"headquarter\"].apply(city_names)\n",
    "# Preview column\n",
    "df_combined[\"headquarter\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Column: stage`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([None, 'Pre-seed', 'Seed', 'Pre-series A', 'Pre-series', 'Series C',\n",
       "       'Series A', 'Series B', 'Debt', 'Pre-series C', 'Pre-series B',\n",
       "       'Series E', 'Bridge', 'Series D', 'Series B2', 'Series F',\n",
       "       'Pre- series A', 'Edge', 'Series H', 'Pre-Series B', 'Seed A',\n",
       "       'Series A-1', 'Seed Funding', 'Pre-Seed', 'Seed round',\n",
       "       'Pre-seed Round', 'Seed Round & Series A', 'Pre Series A',\n",
       "       'Pre seed Round', 'Angel Round', 'Pre series A1', 'Series E2',\n",
       "       'Pre series A', 'Seed Round', 'Bridge Round', 'Pre seed round',\n",
       "       'Pre series B', 'Pre series C', 'Seed Investment', 'Series D1',\n",
       "       'Mid series', 'Series C, D', 'Seed funding', nan, 'Seed+',\n",
       "       'Series F2', 'Series A+', 'Series G', 'Series B3', 'PE',\n",
       "       'Series F1', 'Pre-series A1', 'Early seed', 'Seies A', 'Series A2',\n",
       "       'Series I', 'Angel', 'Private Equity', 'Venture - Series Unknown',\n",
       "       'Grant', 'Debt Financing', 'Post-IPO Debt', 'Corporate Round',\n",
       "       'Undisclosed',\n",
       "       'https://docs.google.com/spreadsheets/d/1x9ziNeaz6auNChIHnMI8U6kS7knTr3byy_YBGfQaoUA/edit#gid=1861303593',\n",
       "       'Secondary Market', 'Post-IPO Equity', 'Non-equity Assistance',\n",
       "       'Funding Round', 'Fresh funding', 'Post series A', 'Seed fund',\n",
       "       'Series B+'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined[\"stage\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorise Stages of funding according to the Indian Startup Ecosystem [Funding Guide](https://www.startupindia.gov.in/content/sih/en/funding.html) \n",
    "\n",
    "| Stages Classification | Description | Stages of funding per Data given |\n",
    "|----------|-----------|-----------|\n",
    "| Ideation | Brainstorming and developing business concepts, defining value propositions, and outlining plans | Pre-seed, Pre-Seed, Pre seed Round, Early seed, Pre-seed Round, Pre seed round |\n",
    "| Validation | Validating the business model, product-market fit, and scalability through research and feedback | Angel, Seed, Seed A, Seed Funding, Seed round, Seed Round, Seed Round & Series A, Seed Investment, Angel Round, Seed fund, Seed funding, Seed+, Grant, Corporate Round |\n",
    "| Early Traction | Gaining initial traction, attracting early adopters, and refining based on feedback | Series A, Series A-1, Series A+, Series A2, Seies A, Pre-Series A, Pre-series A, Pre series A1, Pre-series A1, Post series A, Pre Series A, Pre series A, Pre-series, Pre- series A, Venture - Series Unknown |\n",
    "| Scaling | Expanding operations, customer base, and market reach for rapid growth | Series B, Series B2, Series B3, Series C, Series C, D, Series D, Series D1, Series E, Series F, Series F1, Series F2, Series G, Series H, Series I, Mid series, Pre-series B, Pre-Series B, Pre series B, Pre-series C, Pre series C, Bridge, Edge, Series B+, Post-IPO Equity, Debt, Debt Financing, Private Equity (PE), PE, Private Equity |\n",
    "| Exit Options | Considering exit strategies such as mergers, acquisitions, or IPOs | Post-IPO Debt, Bridge Round |\n",
    "| Others | Stages with unknown class | Fresh funding, Funding Round, Non-equity Assistance, Secondary Market, Undisclosed, https://docs.google.com/spreadsheets/d/1x9ziNeaz6auNChIHnMI8U6kS7knTr3byy_YBGfQaoUA/edit#gid=1861303593 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group stages according to the Indian Startup Ecosystem funding stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([None, 'Ideation', 'Validation', 'Early Traction', 'Scaling',\n",
       "       'Exit Options', nan, 'Others'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stage_classification(value):\n",
    "    \"\"\"\n",
    "    Groups stages according to the Indian Startup Ecosystem funding stage\n",
    "    \"\"\"\n",
    "    classification = {\"Ideation\": [\"Pre-seed\", \"Pre-Seed\", \"Pre seed Round\", \"Early seed\", \"Pre-seed Round\", \"Pre seed round\"],\n",
    "                \"Validation\": [\"Angel\", \"Seed\", \"Seed A\", \"Seed Funding\", \"Seed round\", \"Seed Round\", \"Seed Round & Series A\", \"Grant\",\n",
    "                \"Seed Investment\", \"Angel Round\", \"Seed fund\", \"Seed funding\", \"Seed+\",  \"Corporate Round\"],\n",
    "                \"Early Traction\": [\"Series A\", \"Series A-1\", \"Series A+\", \"Series A2\", \"Seies A\", \"Pre-Series A\", \"Pre-series A\", \"Pre- series A\",\n",
    "                \"Venture - Series Unknown\", \"Pre series A1\", \"Pre-series A1\", \"Post series A\", \"Pre Series A\", \"Pre series A\", \"Pre-series\"],\n",
    "                \"Scaling\": [\"Series B+\", \"Series B\", \"Series B2\", \"Series B3\", \"Series C\", \"Series C, D\", \"Series D\", \"Series D1\", \"Series E\",\n",
    "                \"Series F\", \"Series E2\", \"Series F1\", \"Series F2\", \"Series G\", \"Series H\", \"Series I\", \"Mid series\", \"Bridge\", \"Edge\", \"Pre-series C\",\n",
    "                \"Pre series C\", \"Pre-series B\", \"Pre-Series B\", \"Pre series B\", \"Private Equity (PE)\", \"PE\", \"Private Equity\"],\n",
    "                \"Exit Options\": [\"Post-IPO Debt\", \"Post-IPO Equity\", \"Debt\", \"Debt Financing\", \"Bridge Round\"],\n",
    "                \"Others\": [\"Fresh funding\", \"Funding Round\", \"Non-equity Assistance\", \"Secondary Market\", \"Undisclosed\",\n",
    "                           \"https://docs.google.com/spreadsheets/d/1x9ziNeaz6auNChIHnMI8U6kS7knTr3byy_YBGfQaoUA/edit#gid=1861303593\"]}\n",
    "    \n",
    "    # Put stages under class\n",
    "    for classes, stage in classification.items():\n",
    "        if value in stage:\n",
    "            value = classes\n",
    "    return value\n",
    "\n",
    "# Apply function to column\n",
    "df_combined[\"stage\"] = df_combined[\"stage\"].apply(stage_classification)\n",
    "# Preview column\n",
    "df_combined[\"stage\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Column: sector`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AgriTech', 'EdTech', 'Hygiene management', 'Escrow',\n",
       "       'Networking platform', 'FinTech', 'Crowdsourcing',\n",
       "       'Food & Bevarages', 'HealthTech', 'Fashion startup',\n",
       "       'Food Industry', 'Food Delivery', 'Virtual auditing startup',\n",
       "       'E-commerce', 'Gaming', 'Work fulfillment', 'AI startup',\n",
       "       'Telecommunication', 'Logistics', 'Tech Startup', 'Sports',\n",
       "       'Retail', 'Medtech', 'Tyre management', 'Cloud company',\n",
       "       'Software company', 'Venture capitalist', 'Renewable player',\n",
       "       'IoT startup', 'SaaS startup'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview unique entries in the column\n",
    "df_combined[\"sector\"].unique()[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sectors column has both single and list of categories separated by commas , indicating the multiple sectors a particular business might be involved in. <br>Extract the sector before the first comma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AgriTech', 'EdTech', 'Hygiene management', 'Escrow',\n",
       "       'Networking platform', 'FinTech', 'Crowdsourcing',\n",
       "       'Food & Bevarages', 'HealthTech', 'Fashion startup',\n",
       "       'Food Industry', 'Food Delivery', 'Virtual auditing startup',\n",
       "       'E-commerce', 'Gaming', 'Work fulfillment', 'AI startup',\n",
       "       'Telecommunication', 'Logistics', 'Tech Startup', 'Sports',\n",
       "       'Retail', 'Medtech', 'Tyre management', 'Cloud company',\n",
       "       'Software company', 'Venture capitalist', 'Renewable player',\n",
       "       'IoT startup', 'SaaS startup'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regular expression to capture the first value separated by commas\n",
    "regex = r\"^([^,]+)\"\n",
    "\n",
    "# Function to extract first value if it exists, otherwise return the original single-entry value\n",
    "def extract_first_word(value):\n",
    "    # Convert NoneType value to string to avoid errors when iterating over values\n",
    "    value = str(value)\n",
    "    if \",\" in value:\n",
    "        match = re.match(regex, value)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    return value\n",
    "\n",
    "# Apply the function to the column\n",
    "df_combined[\"sector\"] = df_combined[\"sector\"].apply(extract_first_word)\n",
    "\n",
    "# Preview unique entries in the sector column\n",
    "df_combined[\"sector\"].unique()[:30]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Agriculture & Environment', 'Education & Training',\n",
       "       'Hygiene management', 'Finance sector',\n",
       "       'Communication & Networking', 'Crowdsourcing', 'Food & Beverage',\n",
       "       'Health care', 'Retail & E-commerce', 'Technology sector',\n",
       "       'Media & Entertainment', 'Work fulfillment',\n",
       "       'Logistics & Transportation', 'Industrial & Manufacturing',\n",
       "       'Energy & utility', 'Real Estate & Construction',\n",
       "       'Consumer Services', 'Multinational conglomerate company',\n",
       "       'Publication', 'Entreprenurship', 'WL & RAC protection',\n",
       "       'Social commerce', 'Social Commerce', 'HR', 'None', 'Appliance',\n",
       "       'Location Analytics', 'Hygiene', 'E-connect', 'Consultancy',\n",
       "       'Deisgning', 'Taxation', 'Electronics', 'Tobacco', 'Drone',\n",
       "       'Wholesale', 'Water purification', 'Innovation Management',\n",
       "       'Social audio', 'Human Resources', 'CRM', 'Innovation management',\n",
       "       'Advertisement', 'Cultural', 'Matrimony', 'Analytics', 'Commerce',\n",
       "       'NFT', 'Translation & Localization', 'Design', 'Product studio',\n",
       "       'Mobile Payments', 'Apps', '—', 'Mobile', 'Creative Agency',\n",
       "       'Embedded Systems', 'Classifieds',\n",
       "       'Enterprise Resource Planning (ERP)', 'Audio', 'Government',\n",
       "       'Business Intelligence', 'Children', 'Crowdfunding', 'Catering',\n",
       "       'Fraud Detection', 'Wedding', 'Alternative Medicine', 'Commercial',\n",
       "       'Reading Apps', 'nan'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to categorize industries\n",
    "def categorize_industry(industry):\n",
    "    categories = {\n",
    "        \"Finance sector\": r\"(Accounting|FinTech|Finance|Venture capital|InsureTech|Investment|Financial Services|Banking|Lending|Insurance|Mutual Funds|Capital Markets|Wealth Management|Investment Banking|Online financial service|Escrow)\",\n",
    "        \"Education & Training\": r\"(Provides online learning classes|EdTech|Education|E-learning|Learning|Teaching|Training|School|College|University|Tutoring|Coaching|Classes|Course|Degree|Skills|Edtech|Skill development|EdTech Startup|Education Management|Professional Training|Coaching|Training|Higher Education)\",\n",
    "        \"Agriculture & Environment\": r\"(Fishery|Agri|Agriculture|Farm|Farming|AgTech|Food & Agriculture|Soil-Tech|Environmental|Environment|Sustainability|Sustainable|CleanTech|Green|Pollution|Waste|Recycling|Biomaterials|Environmental Services|Environmental Consulting|Agritech startup|Renewables & Environment|Environmental service|AgriTech)\",\n",
    "        \"Health care\": r\"(Dental|Health|HealthTech|Medtech|Biotechnology|Pharmaceuticals|Healthcare|Dairy startup|Fertility tech|Fitness|Mental Health|Life sciences|Health Insurance|Pharma|Biopharma|Medical|Health care|Diabetes|Medical Device|Health Diagnostics|Hospital)\",\n",
    "        \"Food & Beverage\": r\"(Food|Beverages|Restaurant|Dining|Nutrition|Snack Food|Cafe|Brewery|Bar|Craft Beer|Wine|Spirits|Beer|FoodTech|QSR|Restaurant|Food Production|Food & Beverages|Fusion beverages|Food Industry|Food Delivery|Dairy startup|Beverage)\",\n",
    "        \"Retail & E-commerce\": r\"(Estore|E store|Retail|E-commerce|Marketplace|Online Portals|Retail Tech|E-tail|E-market|D2C|Direct-to-consumer|Shopping|Fashion|Clothing|Apparel|Jewellery|Beauty|Cosmetics|E-store|Furniture|Consumer goods|Consumer Electronics|Consumer|Eyewear|Ecommerce|Retail startup|Retail Aggregator|E-Commerce Platforms|D2C Business|D2C startup|E-marketplace|D2C jewellery|E-Commerce|Consumer Goods|Consumer software|Consumer appliances|Consumer Services)\",\n",
    "        \"Energy & utility\": r\"(Energy|Utility|CleanTech|Renewable Energy|Solar|Wind|Hydro|GreenTech|Energy Storage|Oil|Gas|Renewable player|Energy & utility|Power|Fuel|Electricity|Energy|Energy Management|Energy Efficiency|Solar Monitoring Company|Solar solution)\",\n",
    "        \"Logistics & Transportation\": r\"(Logistics|Transportation|Delivery|Shipping|Freight|Supply Chain|Warehousing|Distribution|Cargo|Trucking|Mobility|Fleet|Parcel|Courier|B2B Supply Chain|Transport|Transport Automation|Last Mile Transportation|Transportation|Mobility/Transport|Vehicle|Bike|Car|Automotive|Auto-tech|EV|Electric Vehicle|Logistics & Supply Chain)\",\n",
    "        \"Real Estate & Construction\": r\"(Accomodation|Real Estate|Property|Housing|Construction|Building|Architecture|Infrastructure|Development|Home|Apartment|House|Commercial Real Estate|Residential|Rental|Co-working|Coworking|Co-living|Interior Design|Home Decor|Real estate|Interior|Construction tech|Real Estate & Construction|Property Management|Housing Marketplace|Real Estate)\",\n",
    "        \"Media & Entertainment\": r\"(FM|Blogging|Online storytelling|Basketball|Games|Online Games|Mobile Games|Media|Entertainment|Content|Music|Video|Streaming|TV|Film|Podcast|Broadcasting|Publishing|News|Digital Media|Social Media|Advertising|Marketing|Gaming|Sports|Events|SportsTech|Media and Entertainment|Digital Entertainment|Visual Media|Online Media|Content creation|Content publishing|Celebrity Engagement)\",\n",
    "        \"Consumer Services\": r\"(Legal|Cooking|Advisory firm|Merchandise|Consumer Services|Service|Hospitality|Hotel|Travel|Tourism|Leisure|Customer|Customer service|Professional Services|Consulting|Home services|Lifestyle|Personal care|Dating|Beauty & wellness|Wellness|Healthcare|Eyeglasses|Consumer Services|Pet care|Veterinary|Personal Care|Tourism|Hotel|Events|Service industry|Recruitment|Staffing|HR Tech startup|HR Tech|Job portal|Job discovery platform)\",\n",
    "        \"Industrial & Manufacturing\": r\"(Aero company|Aeorspace|Automobile|Aviation|Battery|Tyre management|Industrial|Manufacturing|Engineering|Automotive|Machinery|Equipment|Robotics|Industrial Automation|Aerospace|Defense|Construction|Mining|Chemical|Material|Metallurgy|Heavy Industry|Factory|Production|Assembly|Textiles|Construction tech|Manufacturing|Manufacturing startup|Automotive company|Automobile Technology|Industrial Automation|Mechanical Or Industrial Engineering|Mechanical & Industrial Engineering)\",\n",
    "        \"Communication & Networking\": r\"(Communication|Networking|Telecommunication|Network|Platform|Social Network|Messaging|Collaboration|Media & Networking|Network Security|Telecommuncation|Networking platform|Telecommunications|Networking)\",\n",
    "         \"Technology sector\": r\"(Internet|OTT|Data Analytics|Data Intelligence|Android|3D Printing|B2B|Crypto|Data Science|IT|Scanning app|IT company|Tech|AI|IoT|SaaS|Software|Cloud|AR|VR|Blockchain|Automation|Robotics|Cybersecurity|Big Data|Machine Learning|Developer Tools|Information Technology|Computer)\"\n",
    "    }\n",
    "    \n",
    "    for category, pattern in categories.items():\n",
    "        if re.search(pattern, industry, re.IGNORECASE):\n",
    "            return category\n",
    "    return industry\n",
    "\n",
    "# Apply function to the column\n",
    "df_combined[\"sector\"] = df_combined[\"sector\"].apply(categorize_industry)\n",
    "# Preview unique entries in the column\n",
    "df_combined[\"sector\"].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for entries containing only special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_brand</th>\n",
       "      <th>founded</th>\n",
       "      <th>headquarter</th>\n",
       "      <th>sector</th>\n",
       "      <th>what_it_does</th>\n",
       "      <th>founders</th>\n",
       "      <th>investor</th>\n",
       "      <th>amount</th>\n",
       "      <th>stage</th>\n",
       "      <th>year_funded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2300</th>\n",
       "      <td>MissMalini Entertainment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>—</td>\n",
       "      <td>MissMalini Entertainment is a multi-platform n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Validation</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>Jagaran Microfin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>—</td>\n",
       "      <td>Jagaran Microfin is a Microfinance institution...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Exit Options</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2363</th>\n",
       "      <td>FLEECA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jaipur</td>\n",
       "      <td>—</td>\n",
       "      <td>FLEECA is a Tyre Care Provider company.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Validation</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 company_brand  founded headquarter sector  \\\n",
       "2300  MissMalini Entertainment      NaN      Mumbai      —   \n",
       "2347          Jagaran Microfin      NaN     Kolkata      —   \n",
       "2363                    FLEECA      NaN      Jaipur      —   \n",
       "\n",
       "                                           what_it_does founders investor  \\\n",
       "2300  MissMalini Entertainment is a multi-platform n...      NaN      NaN   \n",
       "2347  Jagaran Microfin is a Microfinance institution...      NaN      NaN   \n",
       "2363            FLEECA is a Tyre Care Provider company.      NaN      NaN   \n",
       "\n",
       "      amount         stage year_funded  \n",
       "2300     NaN    Validation  2018-01-01  \n",
       "2347     NaN  Exit Options  2018-01-01  \n",
       "2363     NaN    Validation  2018-01-01  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regular expression to match strings containing only special characters\n",
    "special_chars = r'^[^\\w\\s]+$'\n",
    "\n",
    "# Filter the DataFrame to include only entries with \"what_it_does\" containing only special characters\n",
    "df_combined[df_combined[\"sector\"].str.contains(special_chars, na=False)].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace special characters with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace special characters with null values\n",
    "df_combined[\"sector\"] = df_combined[\"sector\"].replace(\"—\", np.NAN)\n",
    "df_combined[\"sector\"] = df_combined[\"sector\"].replace(\"nan\", np.NAN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Column: founded`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2019., 2018., 2020., 2016., 2008., 2015., 2017., 2014., 1998.,\n",
       "       2007., 2011., 1982., 2013., 2009., 2012., 1995., 2010., 2006.,\n",
       "       1978.,   nan, 1999., 1994., 2005., 1973., 2002., 2004., 2001.,\n",
       "       2021., 1993., 1989., 2000., 2003., 1991., 1984., 1963.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined[\"founded\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for data type\n",
    "df_combined[\"founded\"].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data type is float and needs to be converted to integer and when you apply a function that converts values in a column to integers but also assigns np.nan to invalid entries, the resulting column will be of type float64. This is because np.nan is a floating-point representation of \"Not a Number\" (NaN), and a column in a pandas DataFrame that includes np.nan values will be cast to a floating-point type to accommodate these NaN values.<br>\n",
    "\n",
    "**NB**: As a result, we assign 0 to invalid entries for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_to_integer(value):\n",
    "    try:\n",
    "        # convert the value to an integer\n",
    "        return int(value)\n",
    "    except ValueError:\n",
    "        return 0\n",
    "    \n",
    "# Apply function to coulmn\n",
    "df_combined[\"founded\"] = df_combined[\"founded\"].apply(convert_to_integer)\n",
    "# Confirm datadtype\n",
    "df_combined[\"founded\"].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Column: investor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Angel investors', 'GSF Accelerator', 'Venture Center', ...,\n",
       "       'MyPreferred Transformation, Avendus Finance, SoftBank',\n",
       "       'Norwest Venture Partners, General Catalyst, Fundamentum, Accel Partners',\n",
       "       'TPG, Norwest Venture Partners, Evolvence India'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View unique entries in the column\n",
    "df_combined[\"investor\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for entries containing only special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [company_brand, founded, headquarter, sector, what_it_does, founders, investor, amount, stage, year_funded]\n",
      "Index: []\n",
      "\n",
      "'investor' column has no special character present\n"
     ]
    }
   ],
   "source": [
    "# Regular expression to match strings containing only special characters\n",
    "special_chars = r'^[^\\w\\s]+$'\n",
    "\n",
    "# Filter the DataFrame to include only entries with \"what_it_does\" containing only special characters\n",
    "print(df_combined[df_combined[\"investor\"].str.contains(special_chars, na=False)])\n",
    "\n",
    "print(\"\\n'investor' column has no special character present\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_brand</th>\n",
       "      <th>founded</th>\n",
       "      <th>headquarter</th>\n",
       "      <th>sector</th>\n",
       "      <th>what_it_does</th>\n",
       "      <th>founders</th>\n",
       "      <th>investor</th>\n",
       "      <th>amount</th>\n",
       "      <th>stage</th>\n",
       "      <th>year_funded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>Karnival</td>\n",
       "      <td>2015</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Technology sector</td>\n",
       "      <td>A SAAS platform for retailers and brands to cr...</td>\n",
       "      <td>Neeraj Tyagi</td>\n",
       "      <td>http://100x.vc/</td>\n",
       "      <td>2500000.0</td>\n",
       "      <td>Validation</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     company_brand  founded headquarter             sector  \\\n",
       "1111      Karnival     2015   Bengaluru  Technology sector   \n",
       "\n",
       "                                           what_it_does      founders  \\\n",
       "1111  A SAAS platform for retailers and brands to cr...  Neeraj Tyagi   \n",
       "\n",
       "             investor     amount       stage year_funded  \n",
       "1111  http://100x.vc/  2500000.0  Validation  2021-01-01  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined[df_combined[\"investor\"] == \"http://100x.vc/\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to replace the hyperlink with a null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace hyperlink with null value\n",
    "df_combined[\"investor\"].replace(\"http://100x.vc/\", np.NAN, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Column: what_it_does`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Cultivating Ideas for Profit',\n",
       "       'An academy-guardian-scholar centric ecosystem which provides state of the art technological solutions.',\n",
       "       'Converting bio-hazardous waste to harmless waste', ...,\n",
       "       'Provides rooms for comfortable stay', 'Online car retailer',\n",
       "       'Organised Non-Banking Finance Company'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined[\"what_it_does\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for entries containing only special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [company_brand, founded, headquarter, sector, what_it_does, founders, investor, amount, stage, year_funded]\n",
      "Index: []\n",
      "\n",
      "There is no special character present in the column\n"
     ]
    }
   ],
   "source": [
    "# Regular expression to match strings containing only special characters\n",
    "special_chars = r'^[^\\w\\s]+$'\n",
    "\n",
    "# Filter the DataFrame to include only entries with \"what_it_does\" containing only special characters\n",
    "print(df_combined[df_combined[\"what_it_does\"].str.contains(special_chars, na=False)])\n",
    "print(\"\\nThere is no special character present in the column\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to replace special characters with Null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill Null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Columns: amount, founded`\n",
    "\n",
    "We are going to fill null values in the column. This will be done according to the year startups received funding due to the difference in data characteristics of each dataset.\n",
    "- We filter the datasets by year funded and fill them accordingly.\n",
    "- We fill null values with the median value of each year.<br>\n",
    "\n",
    "**NB**: Mean is affected by outliers and as a result, we use median."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because fillna method does not work in-place on a subset of the DataFrame returned by a condition. Instead, we will handle the operation in a step-by-step manner using a function;\n",
    "- First selecting the rows you want to modify\n",
    "- Applying the fillna\n",
    "- Updating the original DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 292 null value(s) in the 2018 dataset under the amount column\n",
      "There are 12 null value(s) in the 2019 dataset under the amount column\n",
      "There are 253 null value(s) in the 2020 dataset under the amount column\n",
      "There are 141 null value(s) in the 2022 dataset under the amount column\n"
     ]
    }
   ],
   "source": [
    "# Check the number of null values in each dataset under the amount column\n",
    "print(f'There are {df_combined[df_combined[\"year_funded\"] == \"2018\"][\"amount\"].isna().sum()} null value(s) in the 2018 dataset under the amount column')\n",
    "print(f'There are {df_combined[df_combined[\"year_funded\"] == \"2019\"][\"amount\"].isna().sum()} null value(s) in the 2019 dataset under the amount column')\n",
    "print(f'There are {df_combined[df_combined[\"year_funded\"] == \"2020\"][\"amount\"].isna().sum()} null value(s) in the 2020 dataset under the amount column')\n",
    "print(f'There are {df_combined[df_combined[\"year_funded\"] == \"2021\"][\"amount\"].isna().sum()} null value(s) in the 2022 dataset under the amount column')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to fill the null values in the amount column and reaplace (0)s in the founded column with the median  of each dataset now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 null value(s) present in the amount column\n",
      "There are 0 (0)s present in the founded column\n"
     ]
    }
   ],
   "source": [
    "def fillna_with_median(df, condition_column, condition_value, target_column):\n",
    "    \"\"\"\n",
    "    Fills NaN values in the target column with the median of that column,\n",
    "    and returns the updated DataFrame with NaN values filled.\n",
    "    \"\"\"\n",
    "    # Select rows that match the condition\n",
    "    subset_df = df[df[condition_column] == condition_value]\n",
    "    # Compute the median of the target column for these rows\n",
    "    median_value = subset_df[target_column].median()\n",
    "    # Fill NaN values in the target column with the median value\n",
    "    subset_df[target_column].fillna(median_value, inplace=True)\n",
    "    # Replace (0) with \"unknown\"\n",
    "    subset_df[target_column].replace(0, median_value, inplace = True)\n",
    "    # Update the original DataFrame with the modified subset\n",
    "    df.update(subset_df)\n",
    "    return df\n",
    "\n",
    "# Apply function to fill null values\n",
    "fillna_with_median(df_combined, \"year_funded\", \"2018\", \"amount\")\n",
    "fillna_with_median(df_combined, \"year_funded\", \"2019\", \"amount\")\n",
    "fillna_with_median(df_combined, \"year_funded\", \"2020\", \"amount\")\n",
    "fillna_with_median(df_combined, \"year_funded\", \"2021\", \"amount\")\n",
    "\n",
    "# Apply function to replace (0)s with median\n",
    "fillna_with_median(df_combined, \"year_funded\", \"2019\", \"founded\")\n",
    "fillna_with_median(df_combined, \"year_funded\", \"2020\", \"founded\")\n",
    "fillna_with_median(df_combined, \"year_funded\", \"2021\", \"founded\")\n",
    "\n",
    "# Check if null values are filled\n",
    "null_value_count_amount = df_combined[\"amount\"].isna().sum()\n",
    "null_value_count_founded = df_combined[\"founded\"].isna().sum()\n",
    "\n",
    "\n",
    "print(f'There are {null_value_count_amount} null value(s) present in the amount column')\n",
    "print(f'There are {null_value_count_founded} (0)s present in the founded column')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Column: headquarter`\n",
    "Preview null value counts in each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 null value(s) in the 2018 dataset under the headquarter column\n",
      "There are 19 null value(s) in the 2019 dataset under the headquarter column\n",
      "There are 94 null value(s) in the 2020 dataset under the headquarter column\n",
      "There are 3 null value(s) in the 2021 dataset under the headquarter column\n"
     ]
    }
   ],
   "source": [
    "# Check the number of null values in each dataset under the headquarter column\n",
    "print(f'There are {df_combined[df_combined[\"year_funded\"] == \"2018\"][\"headquarter\"].isna().sum()} null value(s) in the 2018 dataset under the headquarter column')\n",
    "print(f'There are {df_combined[df_combined[\"year_funded\"] == \"2019\"][\"headquarter\"].isna().sum()} null value(s) in the 2019 dataset under the headquarter column')\n",
    "print(f'There are {df_combined[df_combined[\"year_funded\"] == \"2020\"][\"headquarter\"].isna().sum()} null value(s) in the 2020 dataset under the headquarter column')\n",
    "print(f'There are {df_combined[df_combined[\"year_funded\"] == \"2021\"][\"headquarter\"].isna().sum()} null value(s) in the 2021 dataset under the headquarter column')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to fill the null values in the headquarter column with the most frequent value (mode) according to the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 null value(s) present in the headquarter column\n"
     ]
    }
   ],
   "source": [
    "def fillna_with_mode(df, condition_column, condition_value, target_column):\n",
    "    \"\"\"\n",
    "    Fills NaN values in the target column with the modal value of that column,\n",
    "    and returns the updated DataFrame with NaN values filled.\n",
    "    \"\"\"\n",
    "    # Select rows that match the condition\n",
    "    sub_set = df[df[condition_column] == condition_value]\n",
    "    # Compute the median of the target column for these rows\n",
    "    mode = sub_set[target_column].mode()[0]\n",
    "    # Fill NaN values in the target column with the modal value\n",
    "    sub_set[target_column].fillna(mode, inplace = True)\n",
    "    # Update the original DataFrame with the modified subset\n",
    "    df.update(sub_set)\n",
    "    return df\n",
    "\n",
    "# Apply function to fill null values\n",
    "fillna_with_mode(df_combined, \"year_funded\", \"2019\", \"headquarter\")\n",
    "fillna_with_mode(df_combined, \"year_funded\", \"2020\", \"headquarter\")\n",
    "fillna_with_mode(df_combined, \"year_funded\", \"2021\", \"headquarter\")\n",
    "\n",
    "# Check if null values are filled\n",
    "null_value_count = df_combined[\"headquarter\"].isna().sum()\n",
    "print(f'There are {null_value_count} null value(s) present in the headquarter column')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Column: sector`\n",
    "Preview null value counts in each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 30 null value(s) in the 2018 dataset under the sector column\n",
      "There are 5 null value(s) in the 2019 dataset under the sector column\n",
      "There are 0 null value(s) in the 2020 dataset under the sector column\n",
      "There are 0 null value(s) in the 2021 dataset under the sector column\n"
     ]
    }
   ],
   "source": [
    "# Check the number of null values in each dataset under the sector column\n",
    "print(f'There are {df_combined[df_combined[\"year_funded\"] == \"2018\"][\"sector\"].isna().sum()} null value(s) in the 2018 dataset under the sector column')\n",
    "print(f'There are {df_combined[df_combined[\"year_funded\"] == \"2019\"][\"sector\"].isna().sum()} null value(s) in the 2019 dataset under the sector column')\n",
    "print(f'There are {df_combined[df_combined[\"year_funded\"] == \"2020\"][\"sector\"].isna().sum()} null value(s) in the 2020 dataset under the sector column')\n",
    "print(f'There are {df_combined[df_combined[\"year_funded\"] == \"2021\"][\"sector\"].isna().sum()} null value(s) in the 2021 dataset under the sector column')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to fill the null values in the stage column with the most frequent value (mode) according to the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 null value(s) present in the sector column\n"
     ]
    }
   ],
   "source": [
    "# Apply function to fill null values\n",
    "fillna_with_mode(df_combined, \"year_funded\", \"2018\", \"sector\")\n",
    "fillna_with_mode(df_combined, \"year_funded\", \"2019\", \"sector\")\n",
    "\n",
    "# Check if null values are filled\n",
    "null_value_count = df_combined[\"sector\"].isna().sum()\n",
    "print(f'There are {null_value_count} null value(s) present in the sector column')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Column: stage`\n",
    "Preview null value counts in each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 null value(s) in the 2018 dataset under the stage column\n",
      "There are 46 null value(s) in the 2019 dataset under the stage column\n",
      "There are 462 null value(s) in the 2020 dataset under the stage column\n",
      "There are 422 null value(s) in the 2021 dataset under the stage column\n"
     ]
    }
   ],
   "source": [
    "# Check the number of null values in each dataset under the stage column\n",
    "print(f'There are {df_combined[df_combined[\"year_funded\"] == \"2018\"][\"stage\"].isna().sum()} null value(s) in the 2018 dataset under the stage column')\n",
    "print(f'There are {df_combined[df_combined[\"year_funded\"] == \"2019\"][\"stage\"].isna().sum()} null value(s) in the 2019 dataset under the stage column')\n",
    "print(f'There are {df_combined[df_combined[\"year_funded\"] == \"2020\"][\"stage\"].isna().sum()} null value(s) in the 2020 dataset under the stage column')\n",
    "print(f'There are {df_combined[df_combined[\"year_funded\"] == \"2021\"][\"stage\"].isna().sum()} null value(s) in the 2021 dataset under the stage column')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to fill the null values in the sector column with the most frequent value (mode) according to the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 null value(s) present in the stage column\n"
     ]
    }
   ],
   "source": [
    "# Apply function to fill null values\n",
    "fillna_with_mode(df_combined, \"year_funded\", \"2019\", \"stage\")\n",
    "fillna_with_mode(df_combined, \"year_funded\", \"2020\", \"stage\")\n",
    "fillna_with_mode(df_combined, \"year_funded\", \"2021\", \"stage\")\n",
    "\n",
    "# Check if null values are filled\n",
    "null_value_count = df_combined[\"stage\"].isna().sum()\n",
    "print(f'There are {null_value_count} null value(s) present in the stage column')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Columns: founders, investor`\n",
    "We won't fill these columns in the 2018 dataset with the modal value because it didn't have these columns. They would rather be filled with **unknown**<br>\n",
    "\n",
    "Preview null values in each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 null value(s) in the 2019 dataset under the founders column\n",
      "There are 12 null value(s) in the 2020 dataset under the founders column\n",
      "There are 4 null value(s) in the 2021 dataset under the founders column\n",
      "\n",
      "There are 0 null value(s) in the 2019 dataset under the investor column\n",
      "There are 38 null value(s) in the 2020 dataset under the investor column\n",
      "There are 66 null value(s) in the 2021 dataset under the investor column\n"
     ]
    }
   ],
   "source": [
    "# Check the number of null values in each dataset under the founders column\n",
    "print(f'There are {df_combined[df_combined[\"year_funded\"] == \"2019\"][\"founders\"].isna().sum()} null value(s) in the 2019 dataset under the founders column')\n",
    "print(f'There are {df_combined[df_combined[\"year_funded\"] == \"2020\"][\"founders\"].isna().sum()} null value(s) in the 2020 dataset under the founders column')\n",
    "print(f'There are {df_combined[df_combined[\"year_funded\"] == \"2021\"][\"founders\"].isna().sum()} null value(s) in the 2021 dataset under the founders column')\n",
    "\n",
    "# Check the number of null values in each dataset under the investor column\n",
    "print(f'\\nThere are {df_combined[df_combined[\"year_funded\"] == \"2019\"][\"investor\"].isna().sum()} null value(s) in the 2019 dataset under the investor column')\n",
    "print(f'There are {df_combined[df_combined[\"year_funded\"] == \"2020\"][\"investor\"].isna().sum()} null value(s) in the 2020 dataset under the investor column')\n",
    "print(f'There are {df_combined[df_combined[\"year_funded\"] == \"2021\"][\"investor\"].isna().sum()} null value(s) in the 2021 dataset under the investor column')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to fill the null values in the founders and investor columns with the most frequent value (mode) according to the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 525 null value(s) present in the founders column\n",
      "There are 525 null value(s) present in the investor column\n",
      "\n",
      "NB: The output is giving 525 counts because 2018 has not been filled yet\n"
     ]
    }
   ],
   "source": [
    "# Apply function to fill null values in the fouonders column \n",
    "fillna_with_mode(df_combined, \"year_funded\", \"2019\", \"founders\")\n",
    "fillna_with_mode(df_combined, \"year_funded\", \"2020\", \"founders\")\n",
    "fillna_with_mode(df_combined, \"year_funded\", \"2021\", \"founders\")\n",
    "\n",
    "# Apply function to fill null values in the investor column \n",
    "fillna_with_mode(df_combined, \"year_funded\", \"2020\", \"investor\")\n",
    "fillna_with_mode(df_combined, \"year_funded\", \"2021\", \"investor\")\n",
    "\n",
    "# Check if null values are filled\n",
    "null_value_count_founders = df_combined[\"founders\"].isna().sum()\n",
    "null_value_count_investor = df_combined[\"investor\"].isna().sum()\n",
    "\n",
    "print(f'There are {null_value_count_founders} null value(s) present in the founders column')\n",
    "print(f'There are {null_value_count_investor} null value(s) present in the investor column')\n",
    "\n",
    "# Print statement\n",
    "print(f'\\nNB: The output is giving 525 counts because 2018 has not been filled yet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Column: founded`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 null value(s) present in the investor column\n",
      "There are 0 null value(s) present in the fouonders column\n",
      "There are 0 null value(s) present in the founded column\n"
     ]
    }
   ],
   "source": [
    "def fillna_replace_with_unknown(df, condition_column, condition_value, target_column):\n",
    "    \"\"\"\n",
    "    Fills NaN values in the target column with the \"Unknown\" of that column, replaces (0)s with \"Unknown\"\n",
    "    and returns the updated DataFrame with NaN values filled and (0)s replaced.\n",
    "    \"\"\"\n",
    "    # Select rows that match the condition\n",
    "    sub_set = df[df[condition_column] == condition_value]\n",
    "    # Fill NaN values in the target column with \"Unknown\"\n",
    "    sub_set[target_column].fillna(\"Unknown\", inplace = True)\n",
    "    # Replace (0) with \"unknown\"\n",
    "    sub_set[target_column].replace(0, \"Unknown\", inplace = True)\n",
    "    # Update the original DataFrame with the modified subset\n",
    "    df.update(sub_set)\n",
    "    return df\n",
    "\n",
    "# Apply function to fill null values\n",
    "fillna_replace_with_unknown(df_combined, \"year_funded\", \"2018\", \"investor\")\n",
    "fillna_replace_with_unknown(df_combined, \"year_funded\", \"2018\", \"founders\")\n",
    "fillna_replace_with_unknown(df_combined, \"year_funded\", \"2018\", \"founded\")\n",
    "\n",
    "# Check if null values are filled\n",
    "null_value_count_investor = df_combined[\"investor\"].isna().sum()\n",
    "null_value_count_founders = df_combined[\"founders\"].isna().sum()\n",
    "null_value_count_founded = df_combined[\"founded\"].isna().sum()\n",
    "\n",
    "\n",
    "print(f'There are {null_value_count_investor} null value(s) present in the investor column')\n",
    "print(f'There are {null_value_count_founders} null value(s) present in the fouonders column')\n",
    "print(f'There are {null_value_count_founded} null value(s) present in the founded column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_brand</th>\n",
       "      <th>founded</th>\n",
       "      <th>headquarter</th>\n",
       "      <th>sector</th>\n",
       "      <th>what_it_does</th>\n",
       "      <th>founders</th>\n",
       "      <th>investor</th>\n",
       "      <th>amount</th>\n",
       "      <th>stage</th>\n",
       "      <th>year_funded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aqgromalin</td>\n",
       "      <td>2019</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>Agriculture &amp; Environment</td>\n",
       "      <td>Cultivating Ideas for Profit</td>\n",
       "      <td>Prasanna Manogaran, Bharani C L</td>\n",
       "      <td>Angel investors</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>Early Traction</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Krayonnz</td>\n",
       "      <td>2019</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Education &amp; Training</td>\n",
       "      <td>An academy-guardian-scholar centric ecosystem ...</td>\n",
       "      <td>Saurabh Dixit, Gurudutt Upadhyay</td>\n",
       "      <td>GSF Accelerator</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>Ideation</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PadCare Labs</td>\n",
       "      <td>2018</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Hygiene management</td>\n",
       "      <td>Converting bio-hazardous waste to harmless waste</td>\n",
       "      <td>Ajinkya Dhariya</td>\n",
       "      <td>Venture Center</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>Ideation</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company_brand founded headquarter                     sector  \\\n",
       "0    Aqgromalin    2019  Tamil Nadu  Agriculture & Environment   \n",
       "1      Krayonnz    2019   Bengaluru       Education & Training   \n",
       "2  PadCare Labs    2018        Pune         Hygiene management   \n",
       "\n",
       "                                        what_it_does  \\\n",
       "0                       Cultivating Ideas for Profit   \n",
       "1  An academy-guardian-scholar centric ecosystem ...   \n",
       "2   Converting bio-hazardous waste to harmless waste   \n",
       "\n",
       "                           founders         investor     amount  \\\n",
       "0   Prasanna Manogaran, Bharani C L  Angel investors   200000.0   \n",
       "1  Saurabh Dixit, Gurudutt Upadhyay  GSF Accelerator   100000.0   \n",
       "2                   Ajinkya Dhariya   Venture Center  3000000.0   \n",
       "\n",
       "            stage year_funded  \n",
       "0  Early Traction  2020-01-01  \n",
       "1        Ideation  2020-01-01  \n",
       "2        Ideation  2020-01-01  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview cleaned data set\n",
    "df_combined.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               null_value_count       datatypes\n",
      "company_brand                 0          object\n",
      "founded                       0          object\n",
      "headquarter                   0          object\n",
      "sector                        0          object\n",
      "what_it_does                  0          object\n",
      "founders                      0          object\n",
      "investor                      0          object\n",
      "amount                        0         float64\n",
      "stage                         0          object\n",
      "year_funded                   0  datetime64[ns]\n",
      "\n",
      "============ Data shape ==============\n",
      "\n",
      "The dataset consists of 2856 rows and 10 columns\n",
      "\n",
      "=========== Duplicated rows =================\n",
      " 6\n"
     ]
    }
   ],
   "source": [
    "# Explore the characteristics of the cleaned data\n",
    "print(pd.DataFrame({\"null_value_count\": df_combined.isna().sum(), \"datatypes\": df_combined.dtypes}))\n",
    "print(\"\\n============ Data shape ==============\\n\")\n",
    "print(f\"The dataset consists of {df_combined.shape[0]} rows and {df_combined.shape[1]} columns\")\n",
    "print(\"\\n=========== Duplicated rows =================\\n\", df_combined.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_brand</th>\n",
       "      <th>founded</th>\n",
       "      <th>headquarter</th>\n",
       "      <th>sector</th>\n",
       "      <th>what_it_does</th>\n",
       "      <th>founders</th>\n",
       "      <th>investor</th>\n",
       "      <th>amount</th>\n",
       "      <th>stage</th>\n",
       "      <th>year_funded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2850</td>\n",
       "      <td>2850</td>\n",
       "      <td>2850</td>\n",
       "      <td>2850</td>\n",
       "      <td>2850</td>\n",
       "      <td>2850</td>\n",
       "      <td>2850</td>\n",
       "      <td>2.850000e+03</td>\n",
       "      <td>2850</td>\n",
       "      <td>2850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2214</td>\n",
       "      <td>35</td>\n",
       "      <td>83</td>\n",
       "      <td>69</td>\n",
       "      <td>2691</td>\n",
       "      <td>1981</td>\n",
       "      <td>1773</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>BharatPe</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Technology sector</td>\n",
       "      <td>Provides online learning classes</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Early Traction</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>10</td>\n",
       "      <td>525</td>\n",
       "      <td>1040</td>\n",
       "      <td>488</td>\n",
       "      <td>5</td>\n",
       "      <td>525</td>\n",
       "      <td>525</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1562</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.830113e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-07 04:17:10.736842240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.500000e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.300000e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.375000e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.500000e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.101222e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       company_brand  founded headquarter             sector  \\\n",
       "count           2850     2850        2850               2850   \n",
       "unique          2214       35          83                 69   \n",
       "top         BharatPe  Unknown   Bengaluru  Technology sector   \n",
       "freq              10      525        1040                488   \n",
       "mean             NaN      NaN         NaN                NaN   \n",
       "min              NaN      NaN         NaN                NaN   \n",
       "25%              NaN      NaN         NaN                NaN   \n",
       "50%              NaN      NaN         NaN                NaN   \n",
       "75%              NaN      NaN         NaN                NaN   \n",
       "max              NaN      NaN         NaN                NaN   \n",
       "std              NaN      NaN         NaN                NaN   \n",
       "\n",
       "                            what_it_does founders investor        amount  \\\n",
       "count                               2850     2850     2850  2.850000e+03   \n",
       "unique                              2691     1981     1773           NaN   \n",
       "top     Provides online learning classes  Unknown  Unknown           NaN   \n",
       "freq                                   5      525      525           NaN   \n",
       "mean                                 NaN      NaN      NaN  9.830113e+07   \n",
       "min                                  NaN      NaN      NaN  7.500000e+03   \n",
       "25%                                  NaN      NaN      NaN  1.300000e+06   \n",
       "50%                                  NaN      NaN      NaN  3.000000e+06   \n",
       "75%                                  NaN      NaN      NaN  7.375000e+06   \n",
       "max                                  NaN      NaN      NaN  1.500000e+11   \n",
       "std                                  NaN      NaN      NaN  3.101222e+09   \n",
       "\n",
       "                 stage                    year_funded  \n",
       "count             2850                           2850  \n",
       "unique               6                            NaN  \n",
       "top     Early Traction                            NaN  \n",
       "freq              1562                            NaN  \n",
       "mean               NaN  2020-01-07 04:17:10.736842240  \n",
       "min                NaN            2018-01-01 00:00:00  \n",
       "25%                NaN            2020-01-01 00:00:00  \n",
       "50%                NaN            2020-01-01 00:00:00  \n",
       "75%                NaN            2021-01-01 00:00:00  \n",
       "max                NaN            2021-01-01 00:00:00  \n",
       "std                NaN                            NaN  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check statistical summary of the dataset\n",
    "df_combined.describe(include = \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_brand</th>\n",
       "      <th>founded</th>\n",
       "      <th>headquarter</th>\n",
       "      <th>sector</th>\n",
       "      <th>what_it_does</th>\n",
       "      <th>founders</th>\n",
       "      <th>investor</th>\n",
       "      <th>amount</th>\n",
       "      <th>stage</th>\n",
       "      <th>year_funded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>TartanSense</td>\n",
       "      <td>2015</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Technology sector</td>\n",
       "      <td>TartanSense unlocks value for small farm holde...</td>\n",
       "      <td>Jaisimha Rao</td>\n",
       "      <td>FMC, Omnivore, Blume Ventures</td>\n",
       "      <td>5000000.0</td>\n",
       "      <td>Early Traction</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>Kirana247</td>\n",
       "      <td>2018</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Logistics &amp; Transportation</td>\n",
       "      <td>An on-demand FMCG supply chain company leverag...</td>\n",
       "      <td>Tarun Jiwarajka, Pankhuri Jiwarajka</td>\n",
       "      <td>Inflection Point Ventures</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>Early Traction</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>IsGoingOnline</td>\n",
       "      <td>2015</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>Retail &amp; E-commerce</td>\n",
       "      <td>Kochi-based digital catalogue and marketplace ...</td>\n",
       "      <td>Eobin Alex</td>\n",
       "      <td>Unicorn India Ventures, SEA Fund, Devdatt Shah</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>Early Traction</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>Camp K12</td>\n",
       "      <td>2010</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Education &amp; Training</td>\n",
       "      <td>Camp K12 is a global online school for 21st ce...</td>\n",
       "      <td>Anshul Bhagi</td>\n",
       "      <td>Matrix Partners India, Elevation Capital</td>\n",
       "      <td>12000000.0</td>\n",
       "      <td>Early Traction</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>Sporjo</td>\n",
       "      <td>2020</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Media &amp; Entertainment</td>\n",
       "      <td>A one stop destination to build a successful c...</td>\n",
       "      <td>G Srinivvasan</td>\n",
       "      <td>Punit Balan</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>Early Traction</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>SuperGaming</td>\n",
       "      <td>2017</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Media &amp; Entertainment</td>\n",
       "      <td>At SuperGaming, building India's best gaming c...</td>\n",
       "      <td>Roby John, Sanket Nadhani, Navneet Waraich</td>\n",
       "      <td>Skycatcher, AET Fund, BAce Capital, Dream Incu...</td>\n",
       "      <td>5500000.0</td>\n",
       "      <td>Early Traction</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      company_brand founded headquarter                      sector  \\\n",
       "1159    TartanSense    2015   Bengaluru           Technology sector   \n",
       "1160      Kirana247    2018       Delhi  Logistics & Transportation   \n",
       "1162  IsGoingOnline    2015      Kerala         Retail & E-commerce   \n",
       "1163       Camp K12    2010     Gurgaon        Education & Training   \n",
       "1165         Sporjo    2020      Mumbai       Media & Entertainment   \n",
       "1166    SuperGaming    2017        Pune       Media & Entertainment   \n",
       "\n",
       "                                           what_it_does  \\\n",
       "1159  TartanSense unlocks value for small farm holde...   \n",
       "1160  An on-demand FMCG supply chain company leverag...   \n",
       "1162  Kochi-based digital catalogue and marketplace ...   \n",
       "1163  Camp K12 is a global online school for 21st ce...   \n",
       "1165  A one stop destination to build a successful c...   \n",
       "1166  At SuperGaming, building India's best gaming c...   \n",
       "\n",
       "                                        founders  \\\n",
       "1159                                Jaisimha Rao   \n",
       "1160         Tarun Jiwarajka, Pankhuri Jiwarajka   \n",
       "1162                                  Eobin Alex   \n",
       "1163                                Anshul Bhagi   \n",
       "1165                               G Srinivvasan   \n",
       "1166  Roby John, Sanket Nadhani, Navneet Waraich   \n",
       "\n",
       "                                               investor      amount  \\\n",
       "1159                      FMC, Omnivore, Blume Ventures   5000000.0   \n",
       "1160                          Inflection Point Ventures   1000000.0   \n",
       "1162     Unicorn India Ventures, SEA Fund, Devdatt Shah    200000.0   \n",
       "1163           Matrix Partners India, Elevation Capital  12000000.0   \n",
       "1165                                        Punit Balan   2000000.0   \n",
       "1166  Skycatcher, AET Fund, BAce Capital, Dream Incu...   5500000.0   \n",
       "\n",
       "               stage year_funded  \n",
       "1159  Early Traction  2021-01-01  \n",
       "1160  Early Traction  2021-01-01  \n",
       "1162  Early Traction  2021-01-01  \n",
       "1163  Early Traction  2021-01-01  \n",
       "1165  Early Traction  2021-01-01  \n",
       "1166  Early Traction  2021-01-01  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview duplicated rows\n",
    "df_combined[df_combined.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 duplicated rows present\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicated rows\n",
    "df_combined.drop_duplicates(keep = \"first\", inplace = True)\n",
    "\n",
    "# Check if duplicated rows are dropped\n",
    "print(f\"There are {df_combined.duplicated().sum()} duplicated rows present\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Null Hypothesis (Ho):** The sector of a startup has no significant influence on the funding it receives.<br>\n",
    "**Alternative Hypothesis (Ha):** The sector of a startup has significant influence on the funding it receives.\n",
    "\n",
    "For this hyposthesis testing, we take significant value ($\\alpha$) = 0.05\n",
    "\n",
    "We are going to perform ANOVA analysis to check if the sector of a startup has significant influence on the funding it receives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factor: sector\n",
      "p-value: 1.0000\n",
      "Conclusion: Since the p-value is greater than the significance level 0.05, we fail to reject the null hypothesis.\n",
      "This indicates that the sector has no significant influence the funding startups receive.\n",
      "\n",
      "Factor: headquarter\n",
      "p-value: 1.0000\n",
      "Conclusion: Since the p-value is greater than the significance level 0.05, we fail to reject the null hypothesis.\n",
      "This indicates that the headquarter has no significant influence the funding startups receive.\n",
      "\n",
      "Factor: stage\n",
      "p-value: 0.0037\n",
      "Conclusion: Since the p-value is less than the significance level 0.05, we reject the null hypothesis.\n",
      "This indicates that the stage has significant influence the funding startups receive.\n",
      "\n",
      "Factor: what_it_does\n",
      "p-value: 1.0000\n",
      "Conclusion: Since the p-value is greater than the significance level 0.05, we fail to reject the null hypothesis.\n",
      "This indicates that the what_it_does has no significant influence the funding startups receive.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform ANOVA analysis for each factor\n",
    "factors = [\"sector\", \"headquarter\", \"stage\", \"what_it_does\"]\n",
    "\n",
    "model = ols(\"amount ~ C(sector) + C(headquarter) + C(stage) + C(what_it_does)\", data = df_combined).fit()\n",
    "anova_table = sm.stats.anova_lm(model, type = 2)\n",
    "\n",
    "# Define the significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Loop through each factor and its corresponding p-value\n",
    "for factor, p_value in zip(factors, anova_table[\"PR(>F)\"]):\n",
    "    print(f\"Factor: {factor}\")\n",
    "    print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "    if p_value > alpha:\n",
    "        print(f\"Conclusion: Since the p-value is greater than the significance level {alpha}, we fail to reject the null hypothesis.\")\n",
    "        print(f\"This indicates that the {factor} has no significant influence on the funding startups receive.\\n\")\n",
    "    else:\n",
    "        print(f\"Conclusion: Since the p-value is less than the significance level {alpha}, we reject the null hypothesis.\")\n",
    "        print(f\"This indicates that the {factor} has significant influence on the funding startups receive.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While our analysis did not find a significant effect of the sector on funding, this does not rule out the possibility that other factors could influence funding. For example, the stage of the startup development showed a significant p-value, suggesting that it might be a more important factor. Further analysis considering other variables and potential interactions between them could provide more insights into what drives funding amounts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
